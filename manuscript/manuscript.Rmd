---
title             : "Title of the Thesis Goes Here"
shorttitle        : "Short title goes here"

author: 
  - name          : "Alexander Enge"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Rudower Chaussee 18, 12489 Berlin"
    email         : "alexander.enge@hu-berlin.de"

affiliation:
  - id            : "1"
    institution   : "Humboldt-Universit√§t zu Berlin"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : "r-references.bib"
zotero            : "aha"

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

csl               : "apa.csl"
documentclass     : "apa7"
classoption       : "man,11pt"
output:
  papaja::apa6_pdf:
    latex_engine:   "xelatex"

header-includes:
  - \usepackage{setspace}
  - \AtBeginEnvironment{tabular}{\doublespacing}
  - \AtBeginEnvironment{lltable}{\doublespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1,scriptsize}}
  - \raggedbottom
---

```{r setup, include=FALSE}
# Load packages
library(papaja)
library(reticulate)
library(lme4)
library(buildmer)
library(tidyverse)
library(magrittr)
library(cowplot)

# Chunk options
knitr::opts_chunk$set(include = FALSE, fig.align = "center", fig.out = "100%", fig.width = 10)

# Specify Python environment
renv::use_python(type = "virtualenv")

# Bibliography file
r_refs("manuscript/r-references.bib")
```

Introduction section goes here.

# Experiment 1

```{r exp1-preparation}
# Define function for reading and formatting behavioral data
read_behav <- function(txt_fname){
  # Read log file
  dat <- suppressMessages(suppressWarnings(read_tsv(txt_fname)))
  # Rename some columns
  dat %<>% rename(participant = VPNummer, item = StimID) %>%
    # Add a column for the part of the experiment
    mutate(part = case_when(Wdh %in% c(211, 231) ~ "I",
                            Wdh %in% c(212, 232) ~ "II",
                            Wdh %in% c(213, 233) ~ "III",
                            Wdh == 234 ~ "IV") %>% as_factor()) %>%
    # Remove filler stimuli (i.e. well-known objects)
    filter(bek_unbek != "bekannt")
  # Assign stimuli to conditions based on keywords and button presses
  excl_known <- dat %>% filter(part == "I" & Tastencode %in% c(201, 251)) %>% pull(item)
  excl_insight <- dat %>% filter(part == "II" & grepl("richtig", Bed) & !Tastencode %in% c(201, 202, 251, 252)) %>% pull(item)
  excl_naive <- dat %>% filter(part == "II" & grepl("falsch", Bed) & !Tastencode %in% c(203, 204, 253, 254)) %>% pull(item)
  insight <- dat %>% filter(part == "II" & grepl("richtig", Bed) & Tastencode %in% c(201, 202, 251, 252)) %>% pull(item)
  naive <- dat %>% filter(part == "II" & grepl("falsch", Bed) & Tastencode %in% c(203, 204, 253, 254)) %>% pull(item)
  # Create a new condition column, excluding trials with known stimuli or without condition
  dat %<>% mutate(condition = case_when(item %in% excl_known ~ "Excl_known",
                                        item %in% excl_insight ~ "Excl_insight",
                                        item %in% excl_naive ~ "Excl_naive",
                                        item %in% insight ~ "Insight",
                                        item %in% naive ~ "Naive") %>%
                    factor(levels = c("Insight", "Naive", "Excl_insight", "Excl_naive", "Excl_known")))
  # In Experiment 3, we need an additional column for position (upright vs. inverted)
  if("richtig_inv" %in% dat$Bed){
    dat %<>% mutate(position = as_factor(ifelse(grepl("inv", Bed), "Inverted", "Upright"))) %>%
      # Return only relevant columns
      select(part, position, condition, participant, item, RT)
  } else {
    dat %<>% select(part, condition, participant, item, RT)}
  return(dat)}

# Read behavioral data for Experiment 1
fnames_exp1 <- list.files("data/exp1/RT", pattern = ".txt", full.names = TRUE)
data_exp1 <- map(fnames_exp1, read_behav)

# Check average number of stimuli per condition
(stims_exp1 <- map(data_exp1, function(x){table(x$condition)/3}) %>% bind_rows() %>% colMeans())
```

```{python exp1-preprocessing}
# Import libraries
import mne
import glob
import os

# Set parameters for EEG preprocessing
preproc_params = dict(n_components=15, method='fastica',           # ICA parameters
                      l_freq=0.1, h_freq=30,                       # Filter edges
                      event_id={'match': 221, 'mismatch': 222},    # EEG triggers
                      tmin=-0.5, tmax=1.498,                       # Length of epochs
                      baseline=(-0.2,0),                           # Baseline correction
                      reject=dict(eeg=200e-6))                     # Rejection threshold

# # Debug
# locals().update(preproc_params)
# vhdr_fname = 'data/exp1/EEG/Vp0001.vhdr'

# Define function for preprocessing EEG data
def preproc(vhdr_fname, metadata, n_components, method, l_freq, h_freq, event_id, tmin, tmax, baseline, reject):
  # Read EEG data
  raw = mne.io.read_raw_brainvision(vhdr_fname, preload=True)
  # Create virtual EOG channels
  raw = mne.set_bipolar_reference(raw, 'Auge_u', 'Fp1', ch_name='VEOG', drop_refs=False)
  raw = mne.set_bipolar_reference(raw, 'F9', 'F10', ch_name='HEOG', drop_refs=False)
  raw.set_channel_types(mapping={'VEOG': 'eog', 'HEOG': 'eog'})
  # Add EasyCap electrode layout, removing any excessive channels
  montage = mne.channels.make_standard_montage('easycap-M1')
  raw.drop_channels(list(set(raw.ch_names) - set(montage.ch_names) - set(['VEOG', 'HEOG'])))
  raw.set_montage(montage=montage)
  # Re-reference to common average
  raw, _ = mne.set_eeg_reference(raw, 'average')
  # Run ICA on a copy of the data
  filt_raw = raw.copy()
  filt_raw.load_data().filter(l_freq=1, h_freq=None)
  ica = mne.preprocessing.ICA(n_components=n_components, random_state=12345, method=method)
  ica.fit(filt_raw)
  # Remove bad components based on correlations with EOG
  eog_indices, eog_scores = ica.find_bads_eog(raw)
  ica.exclude = eog_indices
  raw = ica.apply(raw)
  # Apply band-pass filter
  raw = raw.filter(l_freq=l_freq, h_freq=h_freq)
  # Epoching including baseline correction
  events, _ = mne.events_from_annotations(raw, verbose=False)
  epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
  # Add behavioral data
  epochs.metadata = metadata
  # Reject bad epochs
  epochs = epochs.drop_bad(reject=reject)
  return epochs

# List raw EEG filenames
fnames_exp1 = sorted(glob.glob('data/exp1/EEG/*.vhdr'))

# Import behavioral data from R
metadata_exp1 = r.data_exp1

# Check if preprocessing was done already (delete the file to re-run)
if os.path.exists('output/exp1-epo.fif'):
  # Read preprocessed data from file
  epochs_exp1 = mne.read_epochs('output/exp1-epo.fif', preload=True)
else:
  # Preprocess EEG data for Experiment 1
  epochs_exp14 = [preproc(vhdr_fname=fname, metadata=meta, **preproc_params) for fname, meta in zip(fnames_exp1, metadata_exp1)]
  # Combine epochs into a single data set
  epochs_exp1 = mne.concatenate_epochs(epochs_exp1)
  # Backup epochs to the output folder
  epochs_exp1.save('output/exp1-epo.fif')

# # Get indices of bad epochs despite ICA
# rej_exp1 = epochs_exp1.drop_log
# rej_exp1[:] = [item for item in rej_exp1 if item != ['IGNORED']]
# rej_exp1 = [i for i in range(len(rej_exp1)) if rej_exp1[i] != []]

# Define function to compute grand averages per condition
def compute_evokeds(epochs):
  evokeds = dict()
  evokeds_dat = dict()
  # Each part becomes a dictionary of conditions
  for pt in ['I', 'II', 'III']:
    evokeds[pt] = dict()
    evokeds_dat[pt] = dict()
    # Each condition becomes a list of participants
    for cn in ['Insight', 'Naive']:
      evokeds[pt][cn] = list()
      evokeds_dat[pt][cn] = list()
      # For every participant we average trials separately for all parts and conditions
      for vp in epochs.metadata['participant'].unique():
        query = 'participant == "' + vp + '" and part == "' + pt + '" and condition == "' + cn + '"'
        evokeds[pt][cn].append(epochs[query].average())
      # Compute grand averages across participants for this part and condition
      evokeds[pt][cn] = mne.grand_average(evokeds[pt][cn])
      # Export only the actual data for R
      evokeds_dat[pt][cn] = evokeds[pt][cn].data
  return(evokeds, evokeds_dat)

# Compute grand averages for Experiment 1
evokeds_exp1, evokeds_dat_exp1 = compute_evokeds(epochs=epochs_exp1)

# # Plot evoked potentials
# import matplotlib.pyplot as plt
# mne.viz.plot_compare_evokeds(evokeds=evokeds_exp1['II'], picks='P8'); plt.show()
# evokeds_exp1['II']['Insight'].data = evokeds_exp1['II']['Insight'].data - evokeds_exp1['II']['Naive'].data
# evokeds_exp1['II']['Insight'].plot_topomap(times=[0.125, 0.175, 0.5], average=0.05, vmin=-1, vmax=1, cmap='viridis'); plt.show()
```

```{r exp1-analysis}
# Re-import behavioral data
data_exp1 <- py$epochs_exp1$metadata

# Factorize some columns
data_exp1 %<>% mutate(part = factor(part, levels = c("I", "II", "III")),
                      condition = factor(condition, levels = c("Insight", "Naive", "Excl_insight", "Excl_naive", "Excl_known")),
                      participant = factor(participant),
                      item = factor(item))

# Check number of rejected epochs
rejected_exp1 <- data_exp1 %>% group_by(participant) %>% tally() %>% mutate(n = 360 - n) %>% pull(n)
mean(rejected_exp1); median(rejected_exp1); range(rejected_exp1)

# Create vectors with sample time points (in ms) and electrodes
tmin <- py$preproc_params$tmin*1000
tmax <- py$preproc_params$tmax*1000
sfreq <- py$epochs_exp1$info['sfreq']
times <- seq(tmin, tmax, 1000/sfreq)
els <- py$epochs_exp1$ch_names

# Define ERP components of interest
comps <- tibble(name = c("P1", "N1", "N400"),
                start = c(100, 150, 400),
                stop = c(150, 200, 700),
                roi = list(c("PO3", "PO4", "POz", "O1", "O2", "Oz"),
                           c("P7", "P8", "PO7", "PO8", "PO9", "PO10"),
                           c("C1", "C2", "Cz", "CP1", "CP2", "CPz")))

# Define function to compute single-trial mean ERP amplitudes
compute_erps <- function(epochs, els, name, start, stop, roi){
  erps <- epochs[, which(els %in% roi), which(times %in% start:stop)]
  erps <- apply(erps, 1, mean, na.rm = TRUE)
  return(erps)}

# Check if single-trial ERPs were computed already (delete the file to re-run)
if (file.exists("output/exp1-erps.RDS")){
  # Read data from file
  data_exp1 <- readRDS("output/exp1-erps.RDS")
} else {
  # Import epochs from Python, converting Volts to Microvolts
  epochs_exp1 <- py$epochs_exp1$get_data()*1e6
  # Compute single-trial ERPs for Experiment 1
  data_exp1 <- pmap_dfc(comps, compute_erps, epochs = epochs_exp1, els = els) %>%
    set_names(comps$name) %>% cbind(data_exp1, .) %T>% saveRDS("output/exp1-erps.RDS")}

# Remove any trials excluded from conditions
data_exp1 %<>% filter(condition %in% c("Insight", "Naive")) %>% droplevels()

# Contrast coding for condition (insight-naive) and part (2-1, 3-1)
contrasts_condition <- t(cbind(c("Insight" = 1, "Naive" = -1)))
contrasts_part <- t(cbind(c("I" = -1, "II" = 1, "III" = 0), c("I" = 0, "II" = -1, "III" = 1)))
contrasts(data_exp1$condition) <- MASS::ginv(contrasts_condition)
contrasts(data_exp1$part) <- MASS::ginv(contrasts_part)

# Set formula and parameters for linear mixed-effects regression models (LMMs)
form_exp12 <- tabulate.formula(~ part*condition + (part*condition|participant) + (part*condition|item))
form_exp12 %<>% mutate(block = replace(block, is.na(grouping), "fixed"))
ctrl_params <- lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))

# Set formula for follow-up contrasts
specs_exp12 = pairwise ~ condition|part

# Define function to compute LMMs and follow-up contrasts for each component
compute_models <- function(dep, formula, data, control, specs){
  require(emmeans)
  emm_options(lmer.df = "Satterthwaite", lmerTest.limit = Inf)
  build <- buildmer(dep = dep, formula = formula, data = data, control = control, REML = FALSE,
                    ddf = "Satterthwaite", calc.anova = TRUE)
  conts <- emmeans(build@model, specs = specs, infer = TRUE, data = data)$contrasts %>% as.data.frame()
  mod <- list("model" = build@model, "anova" = build@anova, "summary" = build@summary, "contrasts" = conts)
  return(mod)}

# Check if models were computed already (delete the file to re-run)
if (file.exists("output/exp1-stats.RDS")){
  # Read models from file
  models_exp1 <- readRDS("output/exp1-stats.RDS")
} else {
  # Compute LMMs for Experiment 1
  models_exp1 <- map(comps$name, compute_models, formula = form_exp12, data = data_exp1, control = ctrl_params,
                     specs = specs_exp12) %>% set_names(comps$name) %T>% saveRDS("output/exp1-stats.RDS")}
```

## Methods

### Participants

Participants for Experiment 1 were 24 German native speakers (13 female, 11 male) with a mean age of 24 years (range 18 to 31) and no history psychological disorder or treatment. All participants were right-handed according to the Edinburgh inventory [@oldfield1971] and reported normal or corrected-to-normal vision. They gave written informed consent before starting the experiment and received a compensation of ‚Ç¨8 per hour for participating. All experiments subsequently reported were carried out in accordance with the Declaration of Helsinki and approved by the local ethics committee.

### Materials and Procedure

Stimuli for Experiments 1 and 2 consisted of 240 grayscale photographs of real-world objects, 120 of which were well-known everyday objects (e.g.¬†a bicycle, a toothbrush), whereas the other 120 were rare objects presumed to be unfamiliar for the majority of participants (e.g.¬†a galvanometer, an udu drum). A list of all objects can be found in Appendix A. They were presented on a light blue background with a size of 207 √ó 207 pixels on a 19-inch LCD monitor with a resolution of 1,280 √ó 1,024 pixels and a refresh rate of 75 Hz. At a standardized viewing distance of 90 cm, the images of the objects subtended approximately 3.9 degress of participants' horizontal and vertical visual angle.

For each unfamiliar object, a noun--verb pair was selected describing the object's typical function or use in a way that could typically be related to its visual features and their configuration (e.g.¬†current--measuring, pottery--drumming). In the *insight* condition, the presentation of each unfamiliar object was preceded by its respective description, whereas in the *naive* condition, it was preceded by a non-matching description belonging to one of the other objects. In both conditions, the noun and the verb were presented one above the other in black letters on a light blue background. For each participant, half of the unfamiliar objects were presented in the insight condition (i.e.¬†with a matching description) and the other half were presented in the naive condition (i.e.¬†with a non-matching description). All participants saw each unfamiliar object in only one of the two conditions and the assignment of objects to either of the two conditions was counterbalanced across participants. The experiment was programmed and displayed using Presentation¬Æ software (Neurobehavioral Systems, Inc., Berkeley, CA, www.neurobs.com).

Each experimental session consisted of three parts (Figure \@ref(fig:exp1-plot)A). In Part I, after written informed consent was obtained and the EEG was prepared, all 240 familiar and unfamiliar objects were presented once in random order and without verbal descriptions. Each trial consisted of a fixation cross presented in the middle of the screen for 0.5 s, followed by the presentation of the object until participants made a response or until a time out after 3 s. The intertrial interval until the presentation of the next fixation cross was 0.5 s and participants took a self-timed break after each block of 60 objects. The task, which was kept the same throughout all three parts and experiments, was to classify each object using one of four response alternatives: (a) "I know what this is or have a strong assumption," (b) "I have a strong assumption," (c) "I have rather no assumption what this is," or (d) "I do not know what this is and have no assumotion." Participants were asked to respond as quickly and as accurately as possible by pressing one out of four buttons with the index or middle finger of their left or right hand, respectively. The mapping of the rating scale to the four buttons (left to right or right to left) was counterbalanced across participants. Because we were interested in the acquisition of semantic knowledge about novel objects only, all objects for which the participant indicated knowing the object in Part I were excluded from further analysis (`r scales::percent(stims_exp1["Excl_known"]/120, accuracy = 0.1)` of rare objects per participant).

(ref:figure-1-caption) Procedure and results of Experiment 1. (A) In Part I, participants were presented with 120 unfamiliar objects and indicated whether they knew what kind of object they were viewing. In Part II, half of the objects were preceded by a matching description (in purple color for illustration), leading to semantic insight, and the other half with a non-matching description (in petrol color for illustration), leading to naive perception. In Part III, the same objects were presented again without the descriptions. (B) Bar plots and (C) ERP waveforms and scalp topographies separately for objects for which participants experienced semantic insight and naive perception in Parts I, II, and III. Semantic insight was associated with significantly more negative amplitudes in the N1 component in Part II, significantly less negative amplitudes in the N400 component in Parts II and III, and significantly more positive amplitudes in the P1 component in Part III. Error bars show standard errors of the mean. \newline\**p* \< .05. \*\**p* \< .01. \*\*\**p* \< .001.

```{r exp1-plot, include=TRUE, fig.height=12, fig.cap = "(ref:figure-1-caption)"}
# Manually extract significance levels from contrasts for plotting
stars_exp1 = list(P1 = c(I = NA, II = NA, III = "*"),
                  N1 = c(I = NA, II = "**", III = NA),
                  N400 = c(I = NA, II = "***", III = "**"))

# Import grand averaged evoked potentials from Python
evokeds_exp1 <- py$evokeds_dat_exp1

# Retrive locations for the relevant electrodes from standard montage
fname_montage <- list.files(path = "renv/python", pattern = "easycap-M1.txt", recursive = TRUE, full.names = TRUE)
montage <- py$evokeds_exp1$I$Insight$ch_names %>% as_tibble() %>% rename(electrode = value) %>%
  left_join(read.delim(fname_montage) %>% as_tibble() %>% rename(electrode = Site)) %>%
  mutate(x = eegUtils:::deg2rad(Theta) * cos(eegUtils:::deg2rad(Phi)),
         y = eegUtils:::deg2rad(Theta) * sin(eegUtils:::deg2rad(Phi)))

# Define function to plot trial structure
plot_trial <- function(){
  colour_insight <- viridisLite::viridis(1, begin = 0, end = 0)
  colour_naive <- viridisLite::viridis(1, begin = 0.5, end = 0.5)
  trial_I <- ggplot() + coord_fixed() + theme_void() + xlim(c(0, 74)) + ylim(c(-5, 68)) +
    geom_text(aes(x = 37, y = 68, label = "Part I"), size = 14/.pt, family = "Helvetica", fontface = "bold") +
    geom_rect(aes(xmin = 18, xmax = 38, ymin = 13, ymax = 33), color = "black", fill = "white") +
    geom_text(aes(x = 28, y = 23, label = "+"), size = 5, family = "Helvetica", fontface = "bold") +
    geom_text(aes(x = 28, y = 10, label = "0.5 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 36, xmax = 56, ymin = 26, ymax = 46), color = "black", fill = "white") +
    draw_image("materials/exp1/potato_masher.png", x = 36, y = 26, width = 20, height = 20) +
    geom_text(aes(x = 47, y = 23, label = "max. 3 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_segment(aes(x = 46, y = 13, xend = 56, yend = 20.222), arrow = arrow(length = unit(0.2, "cm")), color = "black")
  trial_II <- ggplot() + coord_fixed() + theme_void() + xlim(c(0, 74)) + ylim(c(-5, 68)) +
    geom_text(aes(x = 37, y = 68, label = "Part II"), size = 14/.pt, family = "Helvetica", fontface = "bold") +
    geom_rect(aes(xmin = 0, xmax = 20, ymin = 0, ymax = 20), color = "black", fill = "white") +
    geom_text(aes(x = 10, y = 10.5, label = "+"), size = 5, family = "Helvetica", fontface = "bold") +
    geom_text(aes(x = 10, y = -3, label = "0.5 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 18, xmax = 38, ymin = 13, ymax = 33), color = colour_insight, fill = "white") +
    geom_text(aes(x = 28, y = 23, label = "Potato\nmashing"), color = colour_insight, size = 10/.pt, family = "Helvetica") +
    geom_text(aes(x = 28, y = 10, label = "2.5 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 18, xmax = 38, ymin = 39, ymax = 59), color = colour_naive, fill = "white") +
    geom_text(aes(x = 28, y = 49, label = "Message\nmorsing"), color = colour_naive, size = 10/.pt, family = "Helvetica") +
    geom_text(aes(x = 28, y = 36, label = "or"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 36, xmax = 56, ymin = 26, ymax = 46), color = "black", fill = "white") +
    geom_text(aes(x = 46, y = 34, label = "*"), size = 8, family = "Helvetica") +
    geom_text(aes(x = 46, y = 23, label = "0.5 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 54, xmax = 74, ymin = 39, ymax = 59), color = "black", fill = "white") +
    draw_image("materials/exp1/potato_masher.png", x = 54, y = 39, width = 20, height = 20) +
    geom_text(aes(x = 65, y = 36, label = "max. 3 s"), color = "black", size = 10/.pt, family = "Helvetica", lineheight = 1) +
    geom_segment(aes(x = 28, y = 0, xend = 74, yend = 33.222), arrow = arrow(length = unit(0.2, "cm")), color = "black")
  trial_III <- ggplot() + coord_fixed() + theme_void() + xlim(c(0, 74)) + ylim(c(-5, 68)) +
    geom_text(aes(x = 37, y = 68, label = "Part III"), size = 14/.pt, family = "Helvetica", fontface = "bold") +
    geom_rect(aes(xmin = 18, xmax = 38, ymin = 13, ymax = 33), color = "black", fill = "white") +
    geom_text(aes(x = 28, y = 23, label = "+"), size = 5, family = "Helvetica", fontface = "bold") +
    geom_text(aes(x = 28, y = 10, label = "0.5 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_rect(aes(xmin = 36, xmax = 56, ymin = 26, ymax = 46), color = "black", fill = "white") +
    draw_image("materials/exp1/potato_masher.png", x = 36, y = 26, width = 20, height = 20) +
    geom_text(aes(x = 47, y = 23, label = "max. 3 s"), color = "black", size = 10/.pt, family = "Helvetica") +
    geom_segment(aes(x = 46, y = 13, xend = 56, yend = 20.222), arrow = arrow(length = unit(0.2, "cm")), color = "black")
  plot_grid(trial_I, NULL, trial_II, NULL, trial_III, nrow = 1, rel_widths = c(10, 1, 10, 1, 10))}

# Define function to plot mean ERP amplitudes
plot_bars <- function(data, stars, ymin){
  parts <- map(c("I", "II", "III"), function(part){
    # For which components in the current part do we have a significant effect?
    sig <- map(stars, part) %>% as.data.frame() %>% t() %>% as.data.frame() %>%
      set_colnames("label") %>% rownames_to_column("comp") %>% na.omit()
    # Create bar plot for the current part
    map(c("P1", "N1", "N400"), function(comp){
      p <- data %>% filter(part == !!part) %>%
        Rmisc::summarySEwithin(measurevar = comp, withinvars = "condition", idvar = "participant") %>%
        mutate(comp = !!comp) %>% rename(amplitude = !!comp)}) %>% bind_rows() %>%
      mutate(comp = fct_relevel(comp, "P1", "N1", "N400")) %>%
      ggplot(aes(x = comp, y = amplitude, fill = condition)) +
      # geom_bar(aes(fill = condition), stat = "identity", position = position_dodge()) +
      # annotate("tile", x = sig$comp, y = -0.4, width = 0.45, height = 0.8, colour = "black", fill = "white", size = 0.5) +
      # annotate("rect", xmin = -Inf, xmax = Inf, ymin = -0.2, ymax = Inf, fill = "white") +
      # geom_bar(aes(y = amplitude - se - 0.2), stat = "identity", position = position_dodge()) + scale_fill_manual(values = c("white", "white")) +
      # new_scale_fill() +
      # annotate("label", x = sig$comp, y = -0.96, label = sig$label, size = 7, family = "Helvetica", label.size = 0) +
      geom_bar(aes(fill = condition), stat = "identity", position = position_dodge()) +
      scale_fill_viridis_d(end = 0.5) +
      geom_errorbar(aes(ymin = amplitude - se, ymax = amplitude + se), position = position_dodge(width = 0.9), width = 0.5) +
      annotate("text", x = sig$comp, y = ymin, label = sig$label, size = 6, family = "Helvetica") +
      geom_hline(yintercept = 0) +
      coord_cartesian(ylim = c(ymin, ymin + 7)) +
      ylab("ROI ampl.\n(¬µV)") +
      scale_y_continuous(breaks = seq(trunc(ymin), trunc(ymin) + 6, 2)) +
      theme_classic() +
      theme(legend.position = "none",
            panel.grid = element_blank(),
            axis.ticks = element_line(color = "black"),
            axis.title.x = element_blank(),
            axis.title.y = element_text(family = "Helvetica", color = "black", size = 10),
            axis.text = element_text(family = "Helvetica", color = "black", size = 10),
            plot.margin = margin(t = 0.3, r = 0, b = 0.4, l = 0.2, "cm"))})
  plot_grid(parts[[1]], NULL, parts[[2]], NULL, parts[[3]], nrow = 1, rel_widths = c(10, 1, 10, 1, 10))}

# Define function to plot ERP waveforms and topographies
plot_erps <- function(comps, evokeds, montage, stars){
  pmap(comps, function(name, start, stop, roi){
    # N400 gets a different scale than P1 and N1
    ymin <- ifelse(name == "N400", -3, -4)
    # Loop through parts
    parts <- map(c("I", "II", "III"), function(part){
      # Create (conditions x time points) x electrodes tibble
      data_plot <- evokeds[[part]] %>% map(function(data){
        data %>% "*"(1e6) %>% t() %>% as_tibble(.name_repair = "unique") %>% set_colnames(montage$electrode) %>%
          mutate(.time = times, roi = rowMeans(select(., all_of(roi))))}) %>%
        bind_rows(.id = "condition")
      # Prepare waveform
      wave <- ggplot(data = data_plot, aes(x = .time, y = roi, color = condition)) +
        annotate("rect", xmin = start, xmax = stop, ymin = -Inf, ymax = ymin + 12, fill = "gray90")
      # Shade significant area
      star <- stars[[name]][[part]]
      if (!is.na(star)){
        wave <- wave + geom_ribbon(data = data_plot %>% filter(.time >= start & .time <= stop) %>%
                                     group_by(.time) %>% summarise(ymin = min(roi), ymax = max(roi)),
                                   aes(x = .time, xmin = start, xmax = stop, ymin = ymin, ymax = ymax),
                                   inherit.aes = FALSE, fill = viridisLite::viridis(n = 1, begin = 1))} #+
          #annotate("text", label = star, x = start + (stop - start)/2, y = -3.2, size = 7, family = "Helvetica")}
      # Add waves and styling
      wave <- wave +
        annotate("segment", x = -200, xend = 800, y = 0, yend = 0) +
        annotate("segment", x = 0, xend = 0, y = ymin, yend = ymin + 12) +
        annotate("segment", x = seq(-100, 700, 200), xend = seq(-100, 700, 200), y = -0.3, yend = 0) +
        annotate("segment", x = -12, xend = 0, y = seq(-2, 8, 4), yend = seq(-2, 8, 4)) +
        annotate("text", x = seq(-100, 700, 200), y = -0.9, label = seq(-100, 700, 200), size = 10/.pt, family = "Helvetica") +
        annotate("text", x = -20, y = seq(-2, 8, 4), label = seq(-2, 8, 4), size = 10/.pt, family = "Helvetica", hjust = 1) +
        annotate("text", x = 400, y = ymin + 0.8, label = "Time (ms)", size = 10/.pt, family = "Helvetica", lineheight = 0.9) +
        annotate("text", x = -100, y = 4, label = paste(name, "ampl.\n(¬µV)"), size = 10/.pt,
                 family = "Helvetica", angle = 90, lineheight = 0.9) +
        geom_line() +
        scale_color_viridis_d(end = 0.5) +
        coord_cartesian(xlim = c(-200, 800), ylim = c(ymin, ymin + 14), expand = FALSE) +
        theme_void() +
        theme(legend.position = "none")
      # Plot topography
      topo <- data_plot %>% filter(.time >= start & .time <= stop) %>%
        group_by(condition) %>% summarise(across(montage$electrode, mean)) %>%
        pivot_longer(-condition) %>% pivot_wider(names_from = condition) %>%
        transmute(amplitude = Insight - Naive) %>% bind_cols(montage) %>%
        eegUtils::topoplot(limits = c(-1, 1), palette = "viridis", contour = FALSE, highlights = roi, scaling = 0.1) +
        theme(legend.position = "none")
      topo$layers[[3]]$aes_params$size <- topo$layers[[4]]$aes_params$size <- topo$layers[[5]]$aes_params$size <- 0.6
      # Combine waveform and topography
      wave + draw_plot(topo, width = 320, height = 9, x = 500, y = ymin + 6.4)})
    # Compbine plots for the different parts
    plot_grid(parts[[1]], NULL, parts[[2]], NULL, parts[[3]], nrow = 1, rel_widths = c(10, 1, 10, 1, 10))
    # Combine plots for the different components
  }) %>% plot_grid(plotlist = ., nrow = 3)}

# Define functions to plot legends for conditions and topoplots
plot_legends <- function(){
  legend_conditions <- get_legend(tibble(Conditions = c("Insight", "Naive")) %>% ggplot(aes(x = 0, y = 0, fill = Conditions)) +
                                    geom_raster() + scale_fill_viridis_d(end = 0.5) +
                                    theme(legend.direction = "horizontal",
                                          legend.title = element_text(family = "Helvetica", size = 10, face = "bold"),
                                          legend.text = element_text(family = "Helvetica", size = 10),
                                          legend.spacing.x = unit(0.3, "cm")))
  legend_topo <- get_legend(tibble(amplitude = c(-1, 1)) %>% ggplot(aes(x = 0, y = 0, fill = amplitude)) + geom_raster() +
                              labs(fill = "Insight - naive\nampl. (¬µV)") +
                              scale_fill_viridis_c(guide = guide_colorbar(ticks = FALSE, title.position = "left",
                                                                          title.vjust = 1, title.hjust = 0.5)) +
                              theme(legend.direction = "horizontal",
                                    legend.title = element_text(family = "Helvetica", size = 10, face = "bold"),
                                    legend.text = element_text(family = "Helvetica", size = 10),
                                    legend.key.width = unit(0.8, "cm"), legend.spacing.x = unit(0.3, "cm")))
  plot_grid(NULL, legend_conditions, legend_topo, NULL, nrow = 1, rel_widths = c(1, 3, 3, 1))}

# Create plot for Experiment 1
plot_grid(plot_trial(),
          plot_bars(data = data_exp1, stars = stars_exp1, ymin = -1.5),
          plot_erps(comps = comps, evokeds = evokeds_exp1, montage = montage, stars = stars_exp1),
          plot_legends(),
          nrow = 4, rel_heights = c(3, 2, 6, 1), labels = c("A", "B", "C", ""), label_fontfamily = "Helvetica")
```

In Part II, only the 120 unfamiliar objects were presented for a second time, now preceded either by a matching verbal description (in the insight condition) or by a non-matching verbal description (in the naive condition). Each trial consisted of a fixation cross presented for 0.5 s, followed by the presentation of the verbal description for 2.5 s. Then, an asterisk was presented in the middle of the screen for another 0.5 s, followed by the presentation of the object until a response was made or until a time out after 3 s. The objects were presented in blocks of 30 trials so that within each block (a) there were 15 objects from each of the two experimental conditions and (b) objects were heterogeneous in terms of their shape, visual complexity, and functional category (e.g.¬†medical devices, musical instruments). To make sure that insight did (did not) occur in the insight (naive) condition, we excluded any objects from the insight condition if participants indicated not knowing the object or having rather no assumption (despite reading the matching description) and any objects from the naive condition if participants indicated knowing the object or having an assumption (despite reading the non-matching description). This resulted in an average of `r format(round(stims_exp1["Insight"], 1), nsmall = 1)` objects (`r scales::percent(stims_exp1["Insight"]/60, accuracy = 0.1)`) per participant remaining in the insight condition and an average of `r format(round(stims_exp1["Naive"], 1), nsmall = 1)` objects (`r scales::percent(stims_exp1["Naive"]/60, accuracy = 0.1)`) per participant remaining in the naive condition.

In Part III, the unfamiliar objects were presented for a third time with an identical trial structure as in Part I, i.e.¬†without the verbal descriptions. Note that Parts II and III were presented in an interleaved fashion so that after the presentation of one block of 30 objects in Part II (with descriptions), participants took a self-timed break and continued with the same block of 30 objects in Part III (without descriptions) before moving on to the next block consisting of 30 different objects. They continued like this until all four blocks were completed in both Parts II and III. In total, the experiment consisted of 480 trials (120 familiar objects in Part I and 120 unfamiliar objects in Parts I, II, and III) and took participants approximately 35 minutes to complete.

### EEG Recording and Preprocessing

The continuous EEG was recorded from 62 Ag/AgCl scalp electrodes placed according to the extended 10--20 system [@americanelectroencephalographicsociety1991] and referenced online to an external electrode placed on the left mastoid (M1). Two additional external electrodes were placed on the right mastoid (M2) and below the left eye (IO1), respectively. During the recording, electrode impedances were kept below 5 kŒ©. An online bandpass filter with a high-pass time-constant of 10 s (0.016 Hz) and a low-pass cutoff frequency of 1,000 Hz was applied before digitizing the signal at a sampling rate of 500 Hz.

Offline, the data were preprocessed using the MNE software [Version 0.20.8; @gramfort2013] in Python [Version 3.7.7; @vanrossum2009]. First, all scalp electrodes were re-referenced to the common average. Next, artifacts resulting from blinks and eye movements were removed using independent component analysis (ICA). The first 15 components were extracted using the FastICA algorithm [@hyv√§rinen1999] after temporarily low-pass filtering the data at 1 Hz. Those components showing substansive correlations with either of two virtual EOG channels (VEOG: IO1 minus Fp1, HEOG: F9 minus F10) were removed automatically using the *find\_bads\_eog* function. After artifact correction, a zero-phase, non-causal FIR filter with a lower passband edge at 0.1 Hz (transition bandwidth: 0.1 Hz) and an upper passband edge at 30 Hz (transition bandwidth: 7.5 Hz) was applied. Next, the continuous EEG was epoched into segments of 2,000 ms, starting 500 ms before the onset of the visual presentation of each unfamiliar object. The epochs were baseline-corrected by substracting the average voltage during the 200 ms before stimulus onset. Epochs containing artifacts despite ICA, defined as peak-to-peak amplitudes exceeding 200 ¬µV, were removed from further analysis. This led to the exclusion of an average of `r format(round(mean(rejected_exp1), 1), nsmall = 1)` trials (`r scales::percent(mean(rejected_exp1)/360, accuracy = 0.1)`) per participant (range `r min(rejected_exp1)` to `r max(rejected_exp1)`). Single-trial event-related potentials were computed as the mean amplitude across time windows and regions of interests (ROIs) defined a priori, namely 100--150 ms after object onset at electrodes PO3, PO4, POz, O1, O2, and Oz for the P1 component, 150--200 ms after object onset at electrodes P7, P8, PO7, PO8, PO9, and PO10 for the N1 component, and 400--700 ms at electrodes C1, C2, Cz, CP1, CP2, and CPz for the N400 component.

### Statistical Analysis

The event-related potentials were analyzed on the single trial level using linear mixed-effects regression models [@baayen2008; @fr√∂mer2018]. For the purpose of the present study, these models have a number of desirable properties compared to more traditional approaches, such as analyses of variance (ANOVAs) performed on by-participant grand averages. First, they can account simultanously for the non-independence of data points coming from the same participant or from the same item, whereas the neglect of item as a random variable in ANOVAs leads to anti-conservative test statistics and strictly does not allow for inferences beyond the stimulus set under study [@b√ºrki2018; @judd2012]. Second, they can flexibly deal with unbalanced designs in which the number of trials differs across (combinations of) conditions, which is inevitable in designs where the assignment of trials to conditions is based on the participants' responses rather than on the experimental manipulation [e.g.¬† @fr√∂ber2017].

Three separate models were computed predicting P1, N1, and N400 mean amplitudes, respectively. All models included three fixed effects: (a) the part of the experiment, coded as a sliding difference contrast (i.e.¬†subtracting Part I from Part II and Part II from Part III, the intercept being the grand mean across all three parts), (b) the condition of the trial, coded as a simple contrast (i.e.¬†subtracting the naive from the insight condition, the intercept being the grand mean across both conditions), and (c) the two-way interaction of part and condition. To determine the random effects structure, we always started with a model containing by-participant and by-item random intercepts and random slopes for all fixed effects [@barr2013]. To increase statistical power and to avoid overfitting, we then iteratively removed each term from the random effects and re-added it only if the resulting model fitted the data significanlty worse than the maximal model, as indicated by likelihood ratio tests [@matuschek2017]. All models were fitted in R [Version `r packageVersion("base")`; @R-base] using the lme4 package [Version `r packageVersion("lme4")`; @R-lme4]. The optimizer function *bobyqa* with 2¬∑10^6^ iterations was used for maximum likelihood estimation. Automatic model selection via likelihood ratio tests was performed using the buildmer package [Version `r packageVersion("buildmer")`; @R-buildmer]. Finally, to answer the research question of whether or not semantic insight had an influence on the ERP components within each part, planned follow-up comparisons contrasting the insight against the naive condition within Parts I, II, and III were calculated.

All materials and code for the present experiments can be accessed via the Open Science Framework ([https://osf.io/.../](https://osf.io/myprojects/)).

## Results

Single-trial ERPs were analyzed in response to unfamiliar objects before (Part I), during (Part II), and after (Part III) participants gained semantic insight into what the objects were doing. Half of the objects were preceded by a matching description, fostering semantic insight to occur, whereas the other half were preceded by a non-matching description, leading to naive perception of the object. To make sure participants did indeed experience insight or naive perception, the analysis was constrained by participants' behavioral responses in Part II: Objects presented with a matching description were assigned to the insight condition only if the participant indicated that they knew what the object was (or had an assumption), whereas objects presented with a non-matching description were assigned to the naive condition only if the participant indicated that they did not know what the object was (or had rather no assumption). The analysis focused on differences between the insight and the naive condition in the P1 component (100--150 ms) as an index of lower-level visual perception, the N1 component (150--200 ms) as index of higher-level visual perception, and the N400 component (400--700 ms) as an index of semantic processing.

```{r exp1-table, include=TRUE, results="asis"}
# Define function to print ANOVA-style table
create_table <- function(models, stub.anova, stub.contrasts, caption, note){
  anov <- map(models, function(model){
    data.frame("f" = format(round(model$anova$`F value`, 2), trim = FALSE, nsmall = 2),
               "df" = paste0("(", model$anova$NumDF, ", ", format(round(model$anova$DenDF, 1), trim = TRUE, nsmall = 1), ")"),
               "p" = format(round(model$anova$`Pr(>F)`, 3), trim = FALSE, nsmall = 3)) %>%
      mutate(p = ifelse(p == "0.000", "< .001", substr(p, 2, nchar(p)))) %>% set_rownames(c(stub.anova))})
  anov_print <- anov %>% map(unite, col = fdf, f, df, sep = " ") %>%
    map(add_row, fdf = "\\textit{F} (\\textit{df})", p = "\\textit{p}", .before = 1) %>% bind_cols() %>%
    set_rownames(c("\\textit{Fixed effects}", stub.anova))
  anov %<>% bind_cols() %>% set_colnames(paste(rep(names(models), each = length(names(models))), c("f", "df", "p"), sep = "_")) 
  conts <- map(models, function(model){
    data.frame("est" = format(round(model$contrasts$estimate, 2), trim = FALSE, nsmall = 2),
               "ci" = paste0("[", format(round(model$contrasts$lower.CL, 2), trim = TRUE, nsmall = 2), ", ",
                               format(round(model$contrasts$upper.CL, 2), trim = TRUE, nsmall = 2), "]"),
               "p" = format(round(model$contrasts$`p.value`, 3), trim = FALSE, nsmall = 3)) %>%
      mutate(p = ifelse(p == "0.000", "< .001", substr(p, 2, nchar(p)))) %>% set_rownames(stub.contrasts)})
  conts_print <- conts %>% map(unite, col = estci, est, ci, sep = " ") %>%
    map(add_row, estci = "Est. [95% CI]", p = "\\textit{p}", .before = 1) %>% bind_cols() %>%
    set_rownames(c("\\textit{Insight $-$  naive}", stub.contrasts))
  conts %<>% bind_cols() %>% set_colnames(paste(rep(names(models), each = length(names(models))), c("est", "ci", "p"), sep = "_"))
  cnames <- c("\\textit{Fixed effects}", as.character(anov_print[1,]))
  list(anov_print[2:nrow(anov_print),], conts_print) %>% map(set_colnames, paste0("V", 1:ncol(anov_print))) %>%
    apa_table(col.names = cnames, col_spanners = list("\\textbf{P1}" = 2:3, "\\textbf{N1}" = 4:5, "\\textbf{N400}" = 6:7),
              midrules = nrow(anov_print), font_size = "footnotesize", align = "lcccccc", escape = FALSE,
              caption = caption, note = note) %>% cat()
  return(list("anov" = anov, "conts" = conts))}

# Create table of models for Experiment 1
table_exp1 <- create_table(models = models_exp1,
                           stub.anova = c("Part", "Insight", "Pt. √ó ins."), stub.contrasts = c("Part I", "Part II", "Part III"),
                           caption = "Results of linear mixed-effects regression models for Experiment 1",
                           note = "Pt. = part, ins. = insight, est. = estimate, CI = confidence interval.")
```

Averaged accross conditions, P1, N1, and N400 amplitudes differed as a function of the part of the experiment, all *F*s \> `r table_exp1$anov["Part", "P1_f"]`, all *p*s `r table_exp1$anov["Part", "P1_p"]` (Table \@ref(tab:exp1-table)). In addition, N400 amplitudes differed between the insight and the naive conditions averaged across the three parts of the experiment, *F*`r table_exp1$anov["Insight", "N400_df"]` = `r table_exp1$anov["Insight", "N400_f"]`, *p* `r table_exp1$anov["Insight", "N400_p"]`. Crucially, the part √ó insight interaction was significant in the N1 component, *F*`r table_exp1$anov["Pt. √ó ins.", "N1_df"]` = `r table_exp1$anov["Pt. √ó ins.", "N1_f"]`, *p* = `r table_exp1$anov["Pt. √ó ins.", "N1_p"]`, and in the N400 component, *F*`r table_exp1$anov["Pt. √ó ins.", "N400_df"]` = `r table_exp1$anov["Pt. √ó ins.", "N400_f"]`, *p* `r table_exp1$anov["Pt. √ó ins.", "N400_p"]`, while also being marginally significant in the P1 component, *F*`r table_exp1$anov["Pt. √ó ins.", "P1_df"]` = `r table_exp1$anov["Pt. √ó ins.", "P1_f"]`, *p* = `r table_exp1$anov["Pt. √ó ins.", "P1_p"]`. To answer our main research question, we decomposed these interactions into the differences between the insight and the naive condition within the three different parts of the experiment.

### Effects of Insight in Part I

In Part I, when objects were unfamiliar to the participant and presented without verbal descriptions, no differences emerged between the insight and the naive condition in the P1, N1, or N400 component, all *p*s \> `r table_exp1$conts["Part I", "N400_p"]` (Table \@ref(tab:exp1-table), Figure \@ref(fig:exp1-plot)B--D). On the one hand, this was to be expected given that the critical presentation of the objects with the descriptions (leading to semantic insight vs.¬†naive perception) had not yet taken place. On the other hand, the absence of reliable differences in Part I can be taken as evidence---with the usual caveats when interpreting null effects---that any subsequent effect of insight in Parts II and III cannot be explained solely by visual differences between the objects in the two conditions. Although the presentation of a matching or non-matching description for each object was counterbalanced across participants, the fact that different numbers of objects were excluded from the two conditions based on participants' self report in Part II would have made it possible for such visual differences to emerge as a confounding factor. If they did, however, one would expect to detect them even before any descriptions were presented, which we now know was not the case.

### Effects of Insight in Part II

In Part II, half of the unfamiliar objects were presented with a matching verbal description (in the insight condition) and the other half were presented with a non-matching verbal description (in the naive condition). In response to objects for which participants experienced insight, the amplitude of the N1 component was significantly enlarged (i.e.¬†more negative), *b* = `r table_exp1$conts["Part II", "N1_est"]` ¬µV, *p* = `r table_exp1$conts["Part II", "N1_p"]`, and the amplitude of the N400 component was significantly reduced (i.e.¬†less negative), *b* = `r table_exp1$conts["Part II", "N400_est"]` ¬µV, *p* `r table_exp1$conts["Part II", "N400_p"]`, compared to objects which participants viewed naively. As in Part I, there were no reliable differences in the P1 component, *p* = `r table_exp1$conts["Part II", "P1_p"]`.

### Effects of Insight in Part III

In Part III, the unfamiliar objects were presented for a third time, again without the verbal descriptions (as in Part I) to test whether the occurence of semantic insight had any lasting effects on the processing of the objects. As in Part II, the N400 component remained significantly reduced in response to objects for which semantic insight had occurred, *b* = `r table_exp1$conts["Part III", "N400_est"]` ¬µV, *p* `r table_exp1$conts["Part III", "N400_p"]`, whereas the early effect of insight in the N1 component did not reocurr, *p* = `r table_exp1$conts["Part III", "N1_p"]`. Instead, we now observed an even earlier modulation in the P1 component, which was significantly enlarged (i.e.¬†more positive) in response to objects for which semantic insight had occured, *b* = `r table_exp1$conts["Part III", "P1_est"]` ¬µV, *p* = `r table_exp1$conts["Part III", "P1_p"]`.

## Discussion

In Experiment 1, we measured event-related brain potentials from participants viewing unfamiliar objects before (Part I), while (Part II) and after (Part III) they gained semantic insight into what kind of object they were seeing. To induce insight, half of the objects in Part II were preceded by a matching verbal description of the object's typical function or use, whereas the other half were preceded by a non-matching description (as a naive baseline condition).

Participants' experience of semantic insight in Part II was associated with a significantly enlarged N1 component, indicating that the sudden acquisition of knowledge about the object influenced aspects of its higher-level visual processing [@rossion2011; @tanaka2001]. The fact that this effect did not reocurr in Part III, when the objects were presented once more without descriptions, suggests it being a marker of semantic insight altering object processing online. In contrast, we also observed a modulation of the N400 component, which was reduced for objects when semantic insight was ocurring (in Part II) and remained so when the same objects were presented repeatedly (in Part III). The N400 is often viewed as an index of increased demands for semantic processing [@kutas2011; @rabovsky2018]. Its reduction can thus be interpreted as lowered semantic processing demands in response to unfamiliar objects once participants had unterstood what kind of object they were viewing. Finally, semantic insight was also associated with increased amplitudes in the P1 component, but only once the objects were presented for a third time (in Part III), after the critical presentation during which semantic insight had ocurred (in Part II). This effect, which replicates previous work on obtaining knowledge about previously unfamiliar images [@samaha2018], may be associated with the newly acquired semantic knowledge exerting an influence on lower-level visual perception, either online or through altered visual representations of the objects for which insight had ocurred.

Because of the exploratory nature of the present study and the novelty of the ERP effects observed in Experiment 1, we ran a replication study to assess the robustness of these findings in another samples of participants.

# Experiment 2

## Methods

```{r exp2-preparation}
# Read behavioral data for Experiment 2
fnames_exp2 <- list.files("data/exp2/RT", pattern = ".txt", full.names = TRUE)
data_exp2 <- map(fnames_exp2, read_behav)

# Check average number of stimuli per condition
(stims_exp2 <- map(data_exp2, function(x){table(x$condition)/3}) %>% bind_rows() %>% colMeans())
```

```{python exp2-preprocessing}
# List raw EEG filenames
fnames_exp2 = sorted(glob.glob('data/exp2/EEG/*.vhdr'))

# Import behavioral data from R
metadata_exp2 = r.data_exp2

# Check if preprocessing was done already (delete the file to re-run)
if os.path.exists('output/exp2-epo.fif'):
  # Read preprocessed data from file
  epochs_exp2 = mne.read_epochs('output/exp2-epo.fif', preload=True)
else:
  # Preprocess EEG data for Experiment 2
  epochs_exp2 = [preproc(vhdr_fname=fname, metadata=meta, **preproc_params) for fname, meta in zip(fnames_exp2, metadata_exp2)]
  # Combine epochs into a single data set
  epochs_exp2 = mne.concatenate_epochs(epochs_exp2)
  # Backup epochs to the output folder
  epochs_exp2.save('output/exp2-epo.fif')

# # Get indices of bad epochs despite ICA
# rej_exp2 = epochs_exp2.drop_log
# rej_exp2[:] = [item for item in rej_exp2 if item != ['IGNORED']]
# rej_exp2 = [i for i in range(len(rej_exp2)) if rej_exp2[i] != []]

# Compute grand averages for Experiment 2
evokeds_exp2, evokeds_dat_exp2 = compute_evokeds(epochs=epochs_exp2)
```

```{r exp2-analysis}
# Re-import behavioral data
data_exp2 <- py$epochs_exp2$metadata

# Factorize some columns
data_exp2 %<>% mutate(part = factor(part, levels = c("I", "II", "III")),
                      condition = factor(condition, levels = c("Insight", "Naive", "Excl_insight", "Excl_naive", "Excl_known")),
                      participant = factor(participant),
                      item = factor(item))

# Check number of rejected epochs
rejected_exp2 <- data_exp2 %>% group_by(participant) %>% tally() %>% mutate(n = 360 - n) %>% pull(n)
mean(rejected_exp2); median(rejected_exp2); range(rejected_exp2)

# Check if single-trial ERPs were computed already (delete the file to re-run)
if (file.exists("output/exp2-erps.RDS")){
  # Read data from file
  data_exp2 <- readRDS("output/exp2-erps.RDS")
} else {
  # Import epochs from Python, converting Volts to Microvolts
  epochs_exp2 <- py$epochs_exp2$get_data()*1e6
  # Compute single-trial ERPs for Experiment 2
  data_exp2 <- pmap_dfc(comps, compute_erps, epochs = epochs_exp2, els = els) %>%
    set_names(comps$name) %>% cbind(data_exp2, .) %T>% saveRDS("output/exp2-erps.RDS")}

# Remove any trials excluded from conditions
data_exp2 %<>% filter(condition %in% c("Insight", "Naive")) %>% droplevels()

# Contrast coding for condition (insight-naive) and part (2-1, 3-1)
contrasts(data_exp2$condition) <- MASS::ginv(contrasts_condition)
contrasts(data_exp2$part) <- MASS::ginv(contrasts_part)

# Check if models were computed already (delete the file to re-run)
if (file.exists("output/exp2-stats.RDS")){
  # Read models from file
  models_exp2 <- readRDS("output/exp2-stats.RDS")
} else {
  # Compute LMMs for Experiment 2
  models_exp2 <- map(comps$name, compute_models, formula = form_exp12, data = data_exp2, control = ctrl_params,
                     specs = specs_exp12) %>% set_names(comps$name) %T>% saveRDS("output/exp2-stats.RDS")}
```

### Participants

Participants for Experiment 2 were 24 German native speakers (18 female, 6 male) with a mean age of 23 years (range 19 to 32) who had not participated in Experiment 1. They had no history of psychological disorder or treatment, were right-handed and reported normal or corrected-to-normal vision. They gave written informed consent before starting the experiment and received a compensation of ‚Ç¨8 per hour for participating.

### Materials, Procedure, and Analysis

All materials, procedures, and methods for EEG recording and statistical analysis were identical to Experiment 1. An average of `r scales::percent(stims_exp2["Excl_known"]/120, accuracy = 0.1)` of rare objects per participant was classified as known in Part I and excluded from all further analyses. Based on participants' responses in Part II, an average of `r format(round(stims_exp2["Insight"], 1), nsmall = 1)` objects (`r scales::percent(stims_exp1["Insight"]/60, accuracy = 0.1)` of objects presented with matching a descirption) were assigned to the insight condition and an average of `r format(round(stims_exp2["Naive"], 1), nsmall = 1)` objects (`r scales::percent(stims_exp1["Naive"]/60, accuracy = 0.1)` of objects presented with a non-matching description) were assigned to the naive condition. Automatic rejection of EEG epochs containing artifacts led to the exlucsion of `r format(round(mean(rejected_exp2), 1), nsmall = 1)` trials (`r scales::percent(mean(rejected_exp2)/360, accuracy = 0.1)`) per participant (range `r min(rejected_exp2)` to `r max(rejected_exp2)`).

## Results

```{r exp2-table, include=TRUE, results="asis"}
# # Create table of models for Experiment 2
table_exp2 <- create_table(models_exp2, stub.anova = c("Part", "Insight", "Pt. √ó ins."),
            stub.contrasts = c("Part I", "Part II", "Part III"),
            caption = "Results of linear mixed-effects regression models for Experiment 2",
            note = "Pt. = part, ins. = insight, est. = estimate, CI = confidence interval.")
```

As in Experiment 1, P1, N1, and N400 amplitudes differed between the three different parts of the experiments, all *F*s \> `r table_exp2$anov["Part", "N1_f"]`, all *p*s `r table_exp2$anov["Part", "N1_p"]` (Table \@ref(tab:exp2-table)). Also as in Experiment 1, N400 amplitudes differed between the insight and the naive condition averaged across parts, *F*`r table_exp2$anov["Insight", "N400_df"]` = `r table_exp2$anov["Insight", "N400_f"]`, *p* `r table_exp2$anov["Pt. √ó ins.", "N400_p"]`. The part √ó insight interaction was significant in the P1 component, *F*`r table_exp2$anov["Pt. √ó ins.", "P1_df"]` = `r table_exp2$anov["Pt. √ó ins.", "P1_f"]`, *p* = `r table_exp2$anov["Pt. √ó ins.", "P1_p"]`, and in the N400 component, *F*`r table_exp2$anov["Pt. √ó ins.", "N400_df"]` = `r table_exp2$anov["Pt. √ó ins.", "N400_f"]`, *p* `r table_exp2$anov["Pt. √ó ins.", "N400_p"]`, but not in the N1 component, *F*`r table_exp2$anov["Pt. √ó ins.", "N1_df"]` = `r table_exp2$anov["Pt. √ó ins.", "N1_f"]`, *p* = `r table_exp2$anov["Pt. √ó ins.", "N1_p"]`.

```{r exp2-plot, include=TRUE, fig.height=9, fig.cap = "(ref:figure-2-caption)"}
# Manually extract significance levels from contrasts for plotting
stars_exp2 = list(P1 = c(I = NA, II = NA, III = "*"),
                  N1 = c(I = NA, II = NA, III = NA),
                  N400 = c(I = NA, II = "***", III = NA))

# Import grand averaged evoked potentials from Python
evokeds_exp2 <- py$evokeds_dat_exp2

# Create plot for Experiment 2
plot_grid(plot_bars(data = data_exp2, stars = stars_exp2, ymin = -2.5),
          plot_erps(comps = comps, evokeds = evokeds_exp2, montage = montage, stars = stars_exp2),
          plot_legends(),
          nrow = 3, rel_heights = c(2, 6, 1), labels = c("A", "B", ""), label_fontfamily = "Helvetica")
```

### Effects of Insight in Part I

As in Experiment 1, no differences between objects in the insight and the naive condition emerged in the P1, N1, or N400 component, all *p*s \> `r table_exp2$conts["Part I", "P1_p"]` (Table \@ref(tab:exp2-table), Figure \@ref(fig:exp2-plot)).

(ref:figure-2-caption) Results of Experiment 2. A. Bar plots and B. ERP waveforms and scalp topographies separately for objects for which participants experienced semantic insight and naive perception in Parts I, II, and III. In a direct replication of Experiment 1, the effect of semantic insight on the N400 component in Part II and on the P1 component in Part III remained statistically significant, while the effect on the N1 component in Part II and on the N400 component in Part III remained only marginally significant. \newline\**p* \< .05. \*\*\**p* \< .001.

### Effects of Insight in Part II

As in Experiment 1, the occurence of semantic insight in Part II due to the presentation of objects with matching (vs.¬†non-matching) verbal descriptions was associated with a (marginally) significant enhancement of the N1 component, *b* = `r table_exp2$conts["Part II", "N1_est"]` ¬µV, *p* = `r table_exp2$conts["Part II", "N1_p"]`, and a signficant reduction of the N400 component, *b* = `r table_exp1$conts["Part II", "N400_est"]` ¬µV, *p* `r table_exp1$conts["Part II", "N400_p"]`.

### Effects of Insight in Part III

As in Experiment 1, the presentation of the same unfamiliar objects for a third time (without verbal descriptions as in Part I) led to significantly larger amplitudes in the P1 component in response to objects for which semantic insight had occured, *b* = `r table_exp2$conts["Part III", "P1_est"]` ¬µV, *p* = `r table_exp2$conts["Part III", "P1_p"]`. Also, N400 amplitudes in response to these objects remained reduced, although marginally significant, *b* = `r table_exp2$conts["Part III", "N400_est"]` ¬µV, *p* = `r table_exp2$conts["Part III", "N400_p"]`.

### Joint Analysis of Experiments 1 and 2

In an attempt to maximize statistical power, we combined the ERP data sets from Experiments 1 and 2. This allowed us to determine (a) if the above effects---including the marginally significant ones---were reliable when tested in a larger sample, and (b) if there were significant differences in the ERP amplitudes between Experiments 1 and 2. Methods for statistical analysis were kept unchanged apart from the addition of a new factor denoting the experiment, coded as a simple contrast (i.e.¬†subtracting Experiment 1 from Experiment 2, the intercept being the grand mean across both experiments). This factor and its possible interactions with part, insight, and part √ó insight were included in the linear mixed-effects regression models as fixed effects and as potential by-item random slopes. They were not included as by-participant random slopes since different participants took part in Experiments 1 and 2. Note that, as above, random effects were eventually included only if their omission led to a significant decline in model fit [@matuschek2017, @R-buildmer].

```{r joint-analysis}
# Combine data from Experiments 1 and 2 (requires changing the participant IDs for Experiment 2)
data_joint <- data_exp2 %>%
  mutate(participant = fct_relabel(participant, ~ paste0(., "_2"))) %>%
  bind_rows(data_exp1, ., .id = "experiment") %>%
  mutate(experiment = as_factor(experiment))

# Contrast coding for experiment (2-1), condition (insight-naive), and part (2-1, 3-1)
t(contrasts_experiment <- t(cbind(c("1" = -1, "2" = 1))))
contrasts(data_joint$experiment) <- MASS::ginv(contrasts_experiment)
contrasts(data_joint$condition) <- MASS::ginv(contrasts_condition)
contrasts(data_joint$part) <- MASS::ginv(contrasts_part)

# New formula for LMMs
form_joint <- tabulate.formula(~ part*condition*experiment + (part*condition|participant) + (part*condition*experiment|item))
form_joint %<>% mutate(block = replace(block, is.na(grouping), "fixed"))

# Check if models were computed already (delete the file to re-run)
if (file.exists("output/joint-stats.RDS")){
  # Read models from file
  models_joint <- readRDS("output/joint-stats.RDS")
} else {
  # Compute LMMs for Experiments 1 and 2 combined
  models_joint <- map(comps$name, compute_models, formula = form_joint, data = data_joint, control = ctrl_params,
                      specs = specs_exp12) %>% set_names(comps$name) %T>% saveRDS("output/joint-stats.RDS")}
```

```{r joint-table, include=TRUE, results="asis"}
# Create table of models for Experiments 1 and 2 combined
table_joint <- create_table(models_joint, stub.anova = c("Part", "Insight", "Experiment", "Pt. √ó ins.", "Pt. √ó exp.",
                                                         "Ins. √ó exp.", "Pt. √ó ins. √ó exp."),
                            stub.contrasts = c("Part I", "Part II", "Part III"),
                            caption = "Results of linear mixed-effects regression models for Experiments 1 and 2 combined",
                            note = "Pt. = part, ins. = insight, exp. = experiment, est. = estimate, CI = confidence interval.")
```

As shown in Table \@ref(tab:joint-table), the main effect of the part of the experiment was significant in the P1, N1, and N400 component, all *F*s \> `r table_joint$anov["Part", "P1_f"]`, all *p*s `r table_exp2$anov["Part", "P1_p"]`, as was the main effect of insight in the N400, *F*`r table_joint$anov["Insight", "N400_df"]` = `r table_joint$anov["Insight", "N400_f"]`, *p* `r table_joint$anov["Insight", "N400_p"]`. Furthermore, the part √ó insight interaction was new observed reliably in all three components, all *F*s \> `r table_joint$anov["Pt. √ó ins.", "P1_f"]`, all *p*s \< `r table_joint$anov["Pt. √ó ins.", "P1_p"]`. While there was a main effect of experiment in the N400, *F*`r table_joint$anov["Experiment", "N400_df"]` = `r table_joint$anov["Experiment", "N400_f"]`, *p* = `r table_joint$anov["Experiment", "N400_p"]`, the absence of any reliable interactions of experiment with part or insight indicated that the effect of our experimental manipulations did not differ between Experiments 1 and 2.

Based on the part √ó insight interaction, we again computed follow-up comparisons between the insight and the naive condition within each part, now collapsed across the data from both experiments. This confirmed the absence of any reliable difference between the two conditions in Part I, all *p*s \> `r table_joint$conts["Part I", "N400_p"]`, the significant enhancement of the N1 component in Part II, while insight was ocurring, *b* = `r table_joint$conts["Part II", "N1_est"]` ¬µV, *p* = `r table_joint$conts["Part II", "N1_p"]`, the significant reduction of the N400 component in Parts II, while insight was occurring, *b* = `r table_joint$conts["Part II", "N400_est"]` ¬µV, *p* `r table_joint$conts["Part II", "N400_p"]`, and Part III, after insight had ocurred, *b* `r table_joint$conts["Part III", "N400_est"]` ¬µV, *p* = `r table_joint$conts["Part III", "N400_p"]`, as well as the sigificant enhancement of the P1 component in Part III, after insight had occurred, *b* = `r table_joint$conts["Part III", "P1_est"]` ¬µV, *p* = `r table_joint$conts["Part III", "P1_p"]`.

## Discussion

Experiment 2, a direct replication of Experiment 1, confirmed the impact of gaining semantic insight into previously unfamiliar objects on ERPs associated with lower-level visual perception (P1), higher-level visual perception (N1), and semantic processing (N400). While the enhancement of the N1 component, being more negative in repsonse to objects for which participants were experiencing semantic insight, was present only during the critical presentation of the objects with their verbal descriptions (in Part II), the enhancement of the P1, being more positive in response to these same objects, emerged only after insight had taken place and the objects were presented again in Part III. This indicates a modulation of different stages of visual object perception through semantic knowledge, while and after an understanding of the object has been obtained. Finally, a sustained reduction of the N400 component in response to objects for which participants experienced semantic insight may reflect lower semantic processing demands compared to unfamiliar objects which participants did not yet understand.

# Experiment 3

```{r exp3-preparation}
# Read behavioral data for Experiment 3
fnames_exp3 <- list.files("data/exp3/RT", pattern = ".txt", full.names = TRUE)
data_exp3 <- map(fnames_exp3, read_behav)

# Check average number of stimuli per condition
(stims_exp3 <- map(data_exp3, function(x){
  x %<>% filter(part != "IV")
  table(x$condition)/3
  }) %>% bind_rows() %>% colMeans())
```

```{python exp3-preprocessing}
# List raw EEG filenames
fnames_exp3 = sorted(glob.glob('data/exp3/EEG/*.vhdr'))

# Import behavioral data from R
metadata_exp3 = r.data_exp3

# Update stimulus triggers
preproc_params['event_id'] = {'match/upright': 241, 'match/inverted': 242, 'mismatch/upright': 243, 'mismatch/inverted': 244}

# Check if preprocessing was done already (delete the file to re-run)
if os.path.exists('output/exp3-epo.fif'):
  # Read preprocessed data from file
  epochs_exp3 = mne.read_epochs('output/exp3-epo.fif', preload=True)
else:
  # Preprocess EEG data for Experiment 3
  epochs_exp3 = [preproc(vhdr_fname=fname, metadata=meta, **preproc_params) for fname, meta in zip(fnames_exp3, metadata_exp3)]
  # Combine epochs into a single data set
  epochs_exp3 = mne.concatenate_epochs(epochs_exp3)
  # Backup epochs and evokeds to the output folder
  epochs_exp3.save('output/exp3-epo.fif')

# # Get indices of bad epochs despite ICA
# rej_exp3 = epochs_exp3.drop_log
# rej_exp3[:] = [item for item in rej_exp3 if item != ['IGNORED']]
# rej_exp3 = [i for i in range(len(rej_exp3)) if rej_exp3[i] != []]
```

```{r exp3-analysis, eval=FALSE}
# Re-import behavioral data
data_exp3 <- py$epochs_exp3$metadata

# Factorize some columns
data_exp3 %<>% mutate(part = factor(part, levels = c("I", "II", "III", "IV")),
                      position = factor(position, levels = c("Inverted", "Upright")),
                      condition = factor(condition, levels = c("Insight", "Naive", "Excl_insight", "Excl_naive", "Excl_known")),
                      participant = factor(participant), item = factor(item))

# Check if ERPs were computed already (delete the file to re-run)
if (file.exists("output/exp3-erps.RDS")){
  # Read ERPs from file
  data_exp3 <- readRDS("output/exp3-erps.RDS")
} else {
  # Import epochs from Python, converting Volts to Microvolts (takes a while)
  epochs_exp3 <- py$epochs_exp3$get_data()*1e6
  # Compute single-trial ERPs for Experiment 3
  data_exp3 <- pmap_dfc(comps, compute_erps, epochs = epochs_exp3, els = els) %>%
    set_names(comps$name) %>% cbind(data_exp3, .) %T>% saveRDS("output/exp3-erps.RDS")}

# Remove any trials from part IV
data_exp3 %<>% filter(part != "IV") %>% droplevels()

# Check number of rejected epochs
rejected_exp3 <- data_exp3 %>% group_by(participant) %>% tally() %>% mutate(n = 672 - n) %>% pull(n)
mean(rejected_exp3); median(rejected_exp3); range(rejected_exp3)

# Remove any trials excluded from conditions
data_exp3 %<>% filter(condition %in% c("Insight", "Naive")) %>% droplevels()

# Contrast coding for position (inverted-updright), condition (insight-naive), and part (2-1, 3-1)
t(contrasts_position <- t(cbind(c("Inverted" = 1, "Upright" = -1))))
contrasts(data_exp3$position) <- MASS::ginv(contrasts_position)
contrasts(data_exp3$condition) <- MASS::ginv(contrasts_condition)
contrasts(data_exp3$part) <- MASS::ginv(contrasts_part)

# New formula for LMMs
form_exp3 <- tabulate.formula(~ part*condition*position + (part*condition*position|participant) + (part*condition*position|item))
form_exp3 %<>% mutate(block = replace(block, is.na(grouping), "fixed"))

# New follow-up contrasts
specs_exp3 = pairwise ~ condition|position*part

# Check if models were computed already (delete the file to re-run)
if (file.exists("output/exp3-stats.RDS")){
  # Read models from file
  models_exp3 <- readRDS("output/exp3-stats.RDS")
} else {
  # Compute LMMs for Experiment 3
  models_exp3 <- map(comps$name, compute_models, formula = form_exp3, data = data_exp3, control = ctrl_params,
                     specs = specs_exp3) %>% set_names(comps$name) %T>% saveRDS("output/exp3-stats.RDS")}
```

```{r exp3-table, include=TRUE, results="asis"}
# Create tanle of models for Experiment 3
table_exp3 <- create_table(models_exp3, stub.anova = c("Part", "Insight", "Position", "Pt. √ó ins.", "Pt. √ó pos.",
                                                       "Ins. √ó pos.", "Pt. √ó ins. √ó pos."),
                           stub.contrasts = c("Part I, inverted", "Part I, upright", "Part II, inverted",
                                              "Part II, upright", "Part III, inverted", "Part III, upright"),
                           caption = "Results of linear mixed-effects regression models for Experiment 3",
                           note = "Pt. = part, ins. = insight, pos. = position, est. = estimate, CI = confidence interval.")
```

# General Discussion

General discussion goes here.

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

\endgroup
