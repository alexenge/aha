---
title             : "Instant effects of semantic information on visual perception"
shorttitle        : "Semantically informed perception"

author: 
  - name          : "Alexander Enge"
    affiliation   : "1,2"
    corresponding : "yes"
    address       : "Rudower Chaussee 18, 12489 Berlin, Germany"
    email         : "alexander.enge@hu-berlin.de"
  - name          : "Franziska Süß"
    affiliation   : "3"
  - name          : "Rasha Abdel Rahman"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Humboldt-Universität zu Berlin"
  - id            : "2"
    institution   : "Research Group Learning in Early Childhood, Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig"
  - id            : "3"
    institution   : "Fachhochschule des Mittelstands, Bamberg"

authornote: |  
  Number of pages: 22

  Number of figures: 3

  Number of words: 215 (abstract), 632 (introduction), 1,443 (discussion)

  We would like to thank Nele Langosch for assistance with the preparation of materials and data collection, Olaf Dimigen and the Abdel Rahman Lab for Neurocognitive Psychology at Humboldt-Universität zu Berlin for insightful discussions, as well as Guido Kiecker for technical support.
  This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy (EXC 2002/1 "Science of Intelligence") project number 390523135 as well as grants AB277-5 and AB277-6 to R.A.R.

  The authors declare no competing financial interests.

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

bibliography      : ["manuscript_files/references.bib", "manuscript_files/r-references.bib"]
csl               : "manuscript_files/citation_style.csl"

documentclass     : "apa6"
classoption       : "man,donotrepeattitle"
fontsize          : "10pt"

editor_options: 
  chunk_output_type: console
  
output:
  papaja::apa6_pdf:
    latex_engine: xelatex
  papaja::apa6_docx: default

header-includes:
  - \geometry{a4paper}
  - \raggedbottom
  - \usepackage{orcidlink}
  - \usepackage[all]{nowidow}
  - \captionsetup[figure]{belowskip=10pt}
  - \captionsetup[figure]{font={small,stretch=1},textfont=normalfont}
  - \captionsetup[figure]{labelfont=bf,labelsep=period,name=Figure}
  - \captionsetup[table]{labelfont=bf,labelsep=period,textfont=bf}
  - \usepackage[export]{adjustbox}
  - \usepackage{makecell}
  - \usepackage{setspace}
---

```{r, setup, include=FALSE}
# Load R packages
library(buildmer)
library(emmeans)
library(here)
library(knitr)
library(lmerTest)
library(MASS)
library(scales)
library(papaja)
library(eegUtils)
library(cowplot)
library(parallel)
library(reticulate)
library(tidyverse)
library(magrittr)

# Set global options
options(readr.show_col_types = FALSE)
opts_chunk$set(
  fig.pos = "tp",
  fig.width = 12,
  message = FALSE,
  out.width = "100%",
  warning = FALSE
)

# Specify directory paths
data_dir <- here("data")
files_dir <- here("manuscript_files")
output_dir <- here("output")
report_dir <- here("output/qc_reports")

# Load custom helper functions for creating figures and tables
source(here(files_dir, "helper_functions.R"))

# Re-run steps that take a long time to compute?
run <- list(
  eeg_processing = FALSE,
  mixed_models = FALSE,
  control_analysis = FALSE,
  figures = FALSE
)

# Write R packages to bibliography
r_refs(here(files_dir, "r-references.bib"), append = FALSE)
```

# Abstract

Does our perception of an object change once we discover what function it serves?
We showed human participants (*n* = 48) pictures of unfamiliar objects either together with keywords matching their function, leading to semantically informed perception, or together with non-matching keywords, resulting in naive perception.
We measured event-related potentials (ERPs) to investigate at which stages in the visual processing hierarchy these two types of object perception differed from one another.
We found that semantically informed as compared to naive perception was associated with larger amplitudes in the N170 component (150--200 ms), reduced amplitudes in the N400 component (400--700 ms), and a late decrease in alpha/beta band power.
When the same objects were presented once more without any information, the N400 and event-related power effects persisted, and we also observed enlarged amplitudes in the P1 component (100--150 ms) in response to objects for which semantically informed perception had taken place.
Consistent with previous work, this suggests that obtaining semantic information about previously unfamiliar objects alters aspects of their lower-level visual perception (P1 component), higher-level visual perception (N170 component), and semantic processing (N400 component, event-related power).
Our study is the first to show that these effects are instantaneous, that is, observable within zero to one trial after any semantic information has been presented.

*Key words*: objects; semantic knowledge; visual perception; event-related potentials

\bigskip

# Significance Statement

There has been a long-standing debate about whether or not higher-level cognitive capacities such as semantic knowledge can influence lower-level perceptual processing in a top-down fashion.
Here we could show for the first time that information about the function of previously unfamiliar objects immediately influences cortical processing within less than 200 ms.
Of note, this influence does not require training or experience with the objects and related semantic information.
Therefore, our study is the first to show effects of cognition on perception while ruling out the possibility that prior knowledge merely acts by pre-activating or altering stored visual representations.
Instead, this knowledge seems to alter perception online, thus providing a compelling case against the impenetrability of perception by cognition.

\newpage

# Introduction

Does our perception of an object change once we discover what function it serves?
This question speaks to the long-standing debate about the cognitive (im)penetrability of perception by higher-level capacities such as semantic knowledge or language [@pylyshyn1999].
According to one view, these cognitive capacities kick in only after the retinal input has been processed by a specialized module for visual perception [@firestone2016; @fodor1983].
This module is encapsulated from higher-level inputs and processes visual information in a purely feed-forward fashion, progressing from lower areas with small receptive field sizes to areas representing increasingly complex shapes and, eventually, whole objects [@dicarlo2012].

The cognitive impenetrability hypothesis is challenged by the alternative view that perception dynamically interacts with different cognitive aspects from early on [@ahissar2004; @churchland1994; @clark2013; @lupyan2015; @lupyan2020; @yuille2006].
On the behavioral level, this is supported by psychological studies that found differences in ratings, detection rates, or reaction times for visual stimuli depending on their emotional [e.g., @phelps2016], motivational [e.g., @balcetis2010], linguistic [e.g., @boutonnet2015] or semantic [e.g., @gauthier2003] content.
However, some studies have received legitimate criticism for confounding tentative high-level effects with low-level differences between conditions, as well as for not being able to discern perceptual from post-perceptual (e.g., memory-related) effects [@firestone2016].

On the physiological level, event-related potentials (ERPs) measured from the human EEG can mitigate most of these concerns:
Their excellent temporal resolution makes it possible to probe how early one can detect influences of high-level (e.g., semantic) information.
To this end, participants in previous studies by our lab and others learned to associate visual objects with different amounts of semantic information.
After learning, an orthogonal task was used to compare ERPs in response to objects learned with versus without semantic information.
This revealed differences not only in late ERP components associated with semantic processing (i.e., the N400 component) but also in the visual P1 component [@abdelrahman2008; @maier2019; @samaha2018; @weller2019].
The early peak of this component and its source in the occipital cortex [@abdelrahman2008] point to an immediate effect of semantic knowledge on visual perception.
It is less clear, however, if this tentative top-down effect of semantic cognition on perception acts in an online fashion (i.e., directly modulating perceptual processing), or more indirectly, by altering stored visual representations over the course of learning, which would then get reactivated once the object is reencountered later on.

To answer this question, we measured ERPs in response to unfamiliar objects directly while participants gained a semantic understanding of their function.
We presented half of the objects together with matching keywords, thus allowing participants to understand what kind of object they were viewing, and the other half together with non-matching keywords, thus keeping the perception of the object semantically naive.
We then presented the same objects again to test for downstream effects of semantic information.
We examined the influence of semantic information on ERPs associated with lower-level visual perception (P1 component), higher-level visual perception (N170 component), and semantic processing (N400 component).
We hypothesized that semantic information would have instant effects on visual perception, by which we mean (a) that these effects can already be observed on the same trial as the semantic information is being presented for the first time, and (b) that these effects are found not only in later, higher-level cognition-related ERP components (i.e., N400), but also in earlier, perception-related ERP components (i.e., P1 and/or N170).
We furthermore conducted an exploratory time-frequency analysis to test for effects on event-related power which, unlike ERP effects, do not need to be tightly phase-locked to stimulus onset.

# Materials and Methods

## Participants

Participants were 48 German native speakers (31 female, 17 male) with a mean age of 23.5 years (range 18--32 years) and no history of psychological disorder or treatment.
No a priori power analysis was carried out and the sample size was chosen in line with previous EEG studies on object processing in our lab.
All participants were right-handed according to the Edinburgh inventory [@oldfield1971] and reported normal or corrected-to-normal vision.
They provided written informed consent before starting the experiment and received a monetary compensation of €8 per hour for participating.

## Stimuli

Stimuli consisted of 240 grayscale photographs of real-world objects.
Of these, 120 stimuli were well-known everyday objects (e.g., a bicycle, a toothbrush).
These served as filler stimuli of no interest.
The other 120 stimuli were rare objects presumed to be unfamiliar to the majority of participants (e.g., a galvanometer, an udu drum; see Supplementary Table 1 for example images).
All stimuli were presented on a light blue background with a size of 207 × 207 pixels on a 19-inch LCD monitor with a resolution of 1,280 × 1,024 pixels and a refresh rate of 75 Hz.
At a standardized viewing distance of 90 cm, the images subtended approximately 3.9 degrees of participants' horizontal and vertical visual angle.

For each unfamiliar object, a pair of German keywords (a noun and a verb) was selected, describing the typical function or use of the object in a way that could be related to its visual features and their configuration (e.g., *Stromstärke, messen* [electric current, measuring]; *Tonpott, trommeln* [clay pot, drumming]; see Supplementary Table 1 for more examples).
As our central experimental manipulation, half of the objects were presented together with keywords that correctly matched their respective function, whereas the other half of the objects were presented together with non-matching keywords belonging to one of the other objects.
The matching keywords were expected to induce semantically informed perception, that is, participants suddenly understanding what kind of object they were viewing.
The non-matching keywords were expected to prevent such an understanding and keep the perception of the object semantically naive.
All participants saw each unfamiliar object with only one type of keywords (matching or non-matching).
This assignment of keywords to objects was counterbalanced across participants so that each object was presented with matching keywords (leading to semantically informed perception) and non-matching keywords (leading to naive perception) to an equal number of participants.
The experiment was programmed and displayed using Presentation® software (Neurobehavioral Systems, Inc., Berkeley, CA, www.neurobs.com).

## Experimental Design

The experiment consisted of three phases (see Figure 1A).
In the *pre-insight* phase, after written informed consent had been obtained and the EEG had been prepared, all 240 familiar and unfamiliar objects were presented once in random order and without any keywords.
Each trial consisted of a fixation cross presented in the middle of the screen for 0.5 s, followed by the presentation of the object until participants made a response or until a time out after 3 s.
The inter-trial interval was 0.5 s and participants took a self-timed break after each block of 60 objects.
The task, which was kept the same across all three phases of the experiment, was to classify each object using one of four response alternatives:
(a) *Ich weiß, was das ist, oder habe eine starke Vermutung* [I know what this is or have a strong assumption],
(b) *Ich habe eher eine Vermutung, was das ist* [I rather have an assumption what this is],
(c) *Ich habe eher keine Vermutung, was das ist* [I rather have no assumption what this is], or
(d) *Ich weiß nicht, was das ist, und habe auch keine Vermutung* [I don’t know what this is and have no assumption].
Participants were asked to respond as quickly and as accurately as possible by pressing one out of four buttons with the index or middle finger of their left or right hand, respectively.
The mapping of the rating scale to the four buttons (left to right or right to left) was counterbalanced across participants.

```{r, eeg_processing, include=FALSE}
# Define function for processing behavioral log files
read_log <- function(log_file) {

  # Read the file
  read_tsv(
    log_file,
    col_types = cols(),
    locale = locale(encoding = "latin1")
  ) %>%
    # Recode some columns
    transmute(

      # Phase of the experiment
      phase = factor(Wdh,
        levels = c(211, 212, 213),
        labels = c("Pre-insight", "Insight", "Post-insight")
      ),

      # Keyword conditions
      keywords = factor(Bed,
        levels = c("richtig", "falsch"),
        labels = c("Match", "Non-match")
      ),

      # Behavioral responses
      # 201: "I know what this is or have a strong assumption"  -> Recode as 4
      # 202: "I have an assumption what this is"                -> Recode as 3
      # 203: "I have rather no assumption what this is"         -> Recode as 2
      # 204: "I don't know what this is and have no assumption" -> Recode as 1
      response = 5 - (Tastencode - 200),

      # Reaction times
      rt = RT,

      # Item IDs
      item_id = factor(StimID)
    ) %>%
    # Remove filler items
    drop_na(keywords) -> log

  # Assign items to conditions based on manipulation (matching vs. non-
  # matching keywords) and the responses of the participants
  items_per_condition <- with(log, {
    list(

      # Informed condition: Matching keywords and positive response
      Informed = item_id[
        phase == "Insight" & keywords == "Match" & response %in% c(3, 4)
      ],

      # Naive condition: Non-matching keywords and negative response
      Naive = item_id[
        phase == "Insight" & keywords == "Non-match" & response %in% c(1, 2)
      ],

      # Exclude: Matching keywords and negative response
      Exclude_informed = item_id[
        phase == "Insight" & keywords == "Match" & response %in% c(1, 2)
      ],

      # Exclude: Non-matching keywords and positive response
      Exclude_naive = item_id[
        phase == "Insight" & keywords == "Non-match" & response %in% c(3, 4)
      ],

      # Exclude: Positive response *before* any info was presented
      Exclude_known = item_id[phase == "Pre-insight" & response == 4]
    )
  })

  # Assign these conditions to the trials of all three phases
  log$condition <- NA
  for (condition in names(items_per_condition)) {
    item_id <- items_per_condition[[condition]]
    log$condition[log$item_id %in% item_id] <- condition
  }

  # Sort columns
  log %>%
    select(item_id, phase, condition, response, rt)
}

# Get list of behavioral log files
log_files <- c(
  list.files(here(data_dir, "rt/exp1"), "*.txt", full.names = TRUE),
  list.files(here(data_dir, "rt/exp2"), "*.txt", full.names = TRUE)
)

# Get list of BrainVision EEG header files
vhdr_files <- c(
  list.files(here(data_dir, "eeg/exp1"), "*.vhdr", full.names = TRUE),
  list.files(here(data_dir, "eeg/exp2"), "*.vhdr", full.names = TRUE)
)

# Import EEG pipeline from Python
pipeline <- import("pipeline")

# Extract versions of Python packages
pipeline_version <- pipeline$`__version__`
mne_version <- import("mne")$`__version__`

# (Re-)do the actual preprocessing if requested
if (run$eeg_processing) {

  # Process behavioral data
  logs <- map(log_files, read_log)

  # Process EEG data
  res <- pipeline$group_pipeline(
    vhdr_files = vhdr_files,
    log_files = logs,
    output_dir = output_dir,
    report_dir = report_dir,
    downsample_sfreq = 125.0,
    bad_channels = NULL,
    ica_method = "fastica",
    ica_n_components = 0.99,
    highpass_freq = 0.1,
    lowpass_freq = 30.0,
    triggers = c(221, 222),
    epochs_tmin = -0.5,
    epochs_tmax = 1.5,
    baseline = c(-0.2, 0.0),
    reject_peak_to_peak = 150.0,
    components = list(
      name = list("P1", "N170", "N400"),
      tmin = list(0.1, 0.15, 0.4),
      tmax = list(0.15, 0.2, 0.7),
      roi = list(
        c("PO3", "PO4", "POz", "O1", "O2", "Oz"),
        c("P7", "P8", "PO7", "PO8", "PO9", "PO10"),
        c("C1", "C2", "Cz", "CP1", "CP2", "CPz")
      )
    ),
    average_by = c("phase/condition"),
    perform_tfr = TRUE,
    tfr_subtract_evoked = FALSE,
    tfr_freqs = seq(4, 40, by = 1.0),
    tfr_cycles = seq(2, 20, by = 0.5),
    tfr_mode = "percent",
    tfr_baseline = c(-0.45, -0.05),
    perm_contrasts = list(
      c("Pre-insight/Informed", "Pre-insight/Naive"),
      c("Insight/Informed", "Insight/Naive"),
      c("Post-insight/Informed", "Post-insight/Naive"),
      c("Insight/Informed", "Insight/Exclude_informed")
    ),
    tfr_components = list(
      name = list("alpha_beta"),
      tmin = list(0.6),
      tmax = list(1.2),
      fmin = list(8.0),
      fmax = list(20.0),
      roi = list(c("P3", "P4", "Pz", "PO3", "PO4", "POz"))
    ),
    perm_tmin = -0.4,
    perm_tmax = 1.4
  )
}

# Read single trial data
read_csv(here(output_dir, "trials.csv"), col_types = cols(
  participant_id = col_factor(),
  item_id = col_factor(),
  phase = col_factor(),
  condition = col_factor()
)) %>%
  # Mark unrealistically short RTs
  mutate(rt = ifelse(rt < 200, NA, rt)) -> trials

# Compute number of objects per condition for each participant
with(trials, table(participant_id, condition)) %>%
  `/`(3) %>%
  as.data.frame.matrix() %>%
  rownames_to_column("subject_id") -> objects_per_condition

# Read by-participant ERP averages and channel locations
evokeds <- read_csv(here(output_dir, "ave.csv"))

# Read pipeline configuration
config <- jsonlite::read_json(
  here(output_dir, "config.json"),
  simplifyVector = TRUE, simplifyMatrix = FALSE
)

# Count number of rejected epochs per participant
rejected_epochs <- lengths(config$auto_rejected_epochs)

# Read channel locations
channel_locations <- read_csv(here(output_dir, "channel_locations.csv"))

# Read grand-averaged power
tfr_grand_ave <- read_csv(here(output_dir, "tfr_grand_ave.csv"))

# Read results of cluster-based permutation tests for ERPs
clusters <- read_csv(here(output_dir, "clusters.csv"))

# Read results of cluster-based permutation tests for TFR
tfr_clusters <- read_csv(here(output_dir, "tfr_clusters.csv"))

# Define cluster-level p value threshold
p_cluster <- 0.05 / 3 # Bonferroni-corrected for three phases
```

```{r, mixed_models, include=FALSE}
# Filter relevant conditions for the main analysis
trials %>%
  mutate(condition = factor(condition, levels = c("Informed", "Naive"))) %>%
  drop_na() -> trials_main

# Contrast coding for phase
cbind(
  c(`Pre-insight` = -1, `Insight` = 1, `Post-insight` = 0),
  c(`Pre-insight` = 0, `Insight` = -1, `Post-insight` = 1)
) %>%
  t() %>%
  ginv() -> contrasts(trials_main$phase)

# Contrast coding for condition
cbind(c(`Informed` = 1, `Naive` = -1)) %>%
  t() %>%
  ginv() -> contrasts(trials_main$condition)

# Construct model formula
form <- ~ phase * condition +
  (phase * condition | participant_id) +
  (phase * condition | item_id)

# Define helper function for fitting linear mixed models and computing contrasts
fit_mixed_models <- function(dep, formula, data) {

  # Modify the formula such that fixed effects are always retained
  formula %<>%
    tabulate.formula() %>%
    mutate(block = replace(block, is.na(grouping), "fixed"))

  # Start a CPU cluster so that multiple models can be fitted in parallel
  n_cores <- detectCores()
  cl <- makeCluster(n_cores)

  # Find the best fitting model (see Matuschek et al., 2017, *JML*)
  build <- buildmer(
    buildmerControl = buildmerControl(
      formula, data,
      args = list(control = lme4::lmerControl(
        optimizer = "bobyqa", optCtrl = list(maxfun = 1e6)
      )),
      direction = c("backward", "backward"),
      cl = cl,
      elim = LRTalpha(.20),
      calc.anova = TRUE,
      ddf = "Satterthwaite",
      dep = dep
    )
  )
  stopCluster(cl)

  # Compute marginal means and contrasts
  emm_options(lmer.df = "Satterthwaite", lmerTest.limit = Inf)
  means <- emmeans(build@model, specs = c("phase", "condition"))
  contrasts <- contrast(means, "pairwise", simple = "condition") %>%
    summary(by = NULL, adjust = "bonferroni")

  # Create list of returns
  list(
    model = build@model,
    summary = build@summary,
    anova = build@anova,
    means = means,
    contrasts = contrasts
  )
}

# (Re-)do the actual model fitting if requested
deps <- config$components$name
if (run$mixed_models) {

  # Fit the model for each ERP component
  map(deps, fit_mixed_models, formula = form, data = trials_main) %>%
    set_names(deps) -> models

  # Save models
  saveRDS(models, here(output_dir, "models.RDS"))
} else {

  # Read fitted models
  models <- readRDS(here(output_dir, "models.RDS"))
}

# Extract relevant statistics to print in the main text
map(models, function(model) as_tibble(model$anova, rownames = "effect")) %>%
  bind_rows(.id = "component") %>%
  rename(f_value = `F value`, p_value = `Pr(>F)`) -> anova_table
map(models, function(model) as_tibble(model$contrasts)) %>%
  bind_rows(.id = "component") %>%
  rename(t_value = `t.ratio`, p_value = `p.value`) -> contrast_table
```

```{r, fig1, cache=!run$figures, fig.height=12, fig.cap="(ref:fig1-caption)"}
# Create Figure 1
plot_fig1(files_dir, evokeds, config, channel_locations, models)
```

(ref:fig1-caption) Experimental design and ERP results.
***A***, In the pre-insight phase, participants were presented with 120 unfamiliar objects and indicated if they knew what kind of object they were viewing.
In the insight phase, half of these objects were presented with matching keywords (in red color for illustration), leading to semantically informed perception, and the other half with non-matching keywords (in blue color for illustration), leading to naive perception.
In the post-insight phase, the same objects were presented again without keywords.
***B***, ***C***, ***D***, ERP waveforms and scalp topographies for the P1 component (100--150 ms, ***B***), for the N170 component (150--200 ms, ***C***), and for the N400 component (400--700 ms, ***D***) for objects with semantically informed perception versus naive perception within the three different phases.
Semantically informed perception was associated with more negative amplitudes in the N170 component during the insight phase, less negative amplitudes in the N400 component during the insight and post-insight phases, and more positive amplitudes in the P1 component during the post-insight phase.
The time windows and channels for quantifying the ERP components are highlighted by the gray areas in the ERP waveforms and by the black markers on the scalp topographies, respectively.
Colored ribbons around the ERP waveforms show ± 1 standard error of the mean across participants.
Ampl. = amplitude.\newline
\* $p_\text{corr} < .05$. \*\* $p_\text{corr} < .01$. \*\*\* $p_\text{corr} < .001$.

In the *insight* phase, the 120 unfamiliar objects were presented for a second time, now preceded either by matching keywords (leading to semantically informed perception) or by non-matching keywords (leading to naive perception).
Each trial consisted of a fixation cross presented for 0.5 s, followed by the presentation of the keywords for 2.5 s.
Then, an asterisk was presented in the middle of the screen for another 0.5 s, followed by the presentation of the object until a response was made or until a time out after 3 s.
The objects were presented in blocks of 30 trials so that within each block there were 15 objects from each of the two experimental conditions and so that objects were heterogeneous in terms of their shape, visual complexity, and functional category (e.g., medical devices, musical instruments).

In the *post-insight* phase, the unfamiliar objects were presented for a third time, with the same trial structure as in the pre-insight phase, that is, without any keywords.
The insight and post-insight phases were presented in an interleaved fashion so that after the presentation of one block of 30 objects in the insight phase (with keywords), participants took a self-timed break and continued with the same block of 30 objects in the post-insight phase (without keywords) before moving on to the next block consisting of 30 different objects.
They continued like this until all four blocks were completed in both phases.
In total, the experiment consisted of 480 trials (120 familiar objects in the pre-insight phase and 120 unfamiliar objects in the pre-insight, insight, and post-insight phases).
Participants took approximately 35 minutes to complete the entire experiment.

## Behavioral Data Analysis

We first excluded from all further analyses those objects for which the participant had responded with "I know what this is" in the pre-insight phase (i.e., before any keywords were presented).
This led to the exclusion of an average of `r mean(objects_per_condition$Exclude_known)` objects per participant (= `r percent(mean(objects_per_condition$Exclude_known) / 120, accuracy = 0.1)` of all unfamiliar objects).
Next, to delineate semantically informed and naive perception, the assignment of the remaining objects to one of these two conditions was co-determined by our experimental manipulation (matching versus non-matching keywords) and the behavioral response of the participant in the insight phase (see Figure 1A).
Objects were assigned to the semantically informed condition if and only if they were presented with matching keywords and the participant responded with knowing what the object was or having an assumption.
This was the case for an average of `r mean(objects_per_condition$Informed)` objects per participant (= `r percent(mean(objects_per_condition$Informed) / 60, accuracy = 0.1)` of objects presented with matching keywords).
Complementarily, objects were assigned to the naive condition if and only if they were presented with non-matching keywords and the participant responded with not knowing what the object was or having rather no assumption.
This was the case for an average of `r mean(objects_per_condition$Naive)` objects per participant (= `r percent(mean(objects_per_condition$Naive) / 60, accuracy = 0.1)` of objects presented with non-matching keywords).
This same assignment of objects to conditions based on the insight phase was carried over to the pre-insight and post-insight phases for each participant individually.
This allowed us to test, on the one hand, if the objects from both conditions differed in important aspects even before any keywords were presented (pre-insight phase) and, on the other hand, if the semantic understanding acquired in the insight phase had any down-stream effects on the subsequent perception of the objects (post-insight phase).

## EEG Recording and Preprocessing

The continuous EEG was recorded from 62 Ag/AgCl scalp electrodes placed according to the extended 10--20 system [@americanelectroencephalographicsociety1991] and referenced online to an external electrode placed on the left mastoid (M1).
Two additional external electrodes were placed on the right mastoid (M2) and below the left eye (IO1), respectively.
Electrode impedances were kept below 5 kΩ.
An online band-pass filter with a high-pass time-constant of 10 s (0.016 Hz) and a low-pass cutoff frequency of 1000 Hz was applied before digitizing the signal at a sampling rate of 500 Hz.

The data were preprocessed offline using custom functions (available at [https://github.com/alexenge/hu-neuro-pipeline/tree/v0.6.1](https://github.com/alexenge/hu-neuro-pipeline/tree/v0.6.1)) based on the MNE-Python software [Version `r mne_version`\; @gramfort2013] in Python [Version `r py_version()`\; @vanrossum2009].
First, the data were downsampled to `r config$downsample_sfreq` Hz and re-referenced to the common average of all scalp channels.
Next, artifacts resulting from blinks and eye movements were removed via independent component analysis (ICA) on a low-pass filtered copy of the data (cutoff = 1 Hz).
A variable number of components per participant were extracted from an initial principal component analysis (PCA) so that they explained at least `r percent(config$ica_n_components)` of the variance in the data (mean = `r mean(unlist(config$auto_ica_n_components))` components, range `r min(unlist(config$auto_ica_n_components))`--`r max(unlist(config$auto_ica_n_components))`).
Then the ICA was fitted based on these components using the FastICA algorithm [@hyvarinen1999].
Any independent components showing significant correlations with either of two virtual EOG channels (VEOG: IO1 - Fp1, HEOG: F9 - F10) were removed automatically using MNE-Python's *find_bads_eog* method.
This was the case for an average of `r mean(lengths(config$auto_ica_bad_components))` components per participant (range = `r min(lengths(config$auto_ica_bad_components))`--`r max(lengths(config$auto_ica_bad_components))` components).

For the analysis of ERP amplitudes, a zero-phase, non-causal FIR filter with a lower pass-band edge at `r format(config$highpass_freq, digits = 1)` Hz (transition bandwidth: 0.1 Hz) and an upper pass-band edge at `r config$lowpass_freq` Hz (transition bandwidth: 7.5 Hz) was applied.
Next, the continuous EEG was segmented into epochs ranging from -500 ms to 1,500 ms relative to the onset of the presentation of each unfamiliar object.
These epochs were baseline-corrected by subtracting the average voltage during the interval of -200 ms to 0 ms relative to stimulus onset.
Epochs containing artifacts despite ICA, defined as peak-to-peak amplitudes exceeding `r config$reject_peak_to_peak` µV, were removed from further analysis.
This led to the exclusion of an average of `r mean(rejected_epochs)` trials per participant (= `r percent(mean(rejected_epochs) / 360, accuracy = 0.1)`; range `r min(rejected_epochs)`--`r max(rejected_epochs)` trials).
Single-trial event-related potentials were computed as the mean amplitude across time windows and regions of interests (ROIs) defined a priori, namely 100--150 ms at channels PO3, PO4, POz, O1, O2, and Oz and for the P1 component, 150--200 ms at channels P7, P8, PO7, PO8, PO9, and PO10 for the N170 component, and 400--700 ms at channels C1, C2, Cz, CP1, CP2, and CPz for the N400 component.
We chose a later time window for the N400 component than what is typically used in experiments with verbal materials (e.g., 300--500 ms), in accordance with a previously published data set which showed that the 400--700 ms time window is most robustly associated with the semantic processing of visual objects [@kovalenko2012].

## Statistical Analysis

The resulting mean ERP amplitudes were analyzed on the single-trial level using linear mixed-effects regression models because these models allow to control for repeated measures of participants and stimuli, while also being robust against an unbalanced number of trials per condition [@brown2021; @burki2018; @fromer2018].
We computed three models predicting P1, N170, and N400 amplitudes, respectively.
All models included three fixed effects: (a) the phase of the experiment, coded as a repeated contrast [i.e., subtracting the first phase from the second phase and the second phase from the third phase, the intercept being the grand mean across all three phases\; @schad2020], (b) the condition of the object, coded as a scaled sum contrast (i.e., subtracting the naive condition from the semantically informed condition, the intercept being the grand mean across both conditions), and (c) the two-way interaction of phase and condition.
We determined the most parsimonious random effect structure supported by the data using the automatic procedure proposed by @matuschek2017.
This involved starting with a maximal model that contained all random parameters (intercepts, slopes, and correlations) and then iteratively removing terms as long as this did not result in a significant drop in model fit (likelihood ratio test, $p$ value cutoff = .20; see Supplementary Results 1 for the final model syntax and model outputs).
All models were fitted in R [Version `r as.character(packageVersion("base"))`\; @R-base] using the lme4 package [Version `r as.character(packageVersion("lme4"))`\; @R-lme4] with the optimizer function *bobyqa* and a maximum of 10^6^ iterations for maximum likelihood estimation.
The model selection algorithm via likelihood ratio tests was performed using the buildmer package [Version `r as.character(packageVersion("buildmer"))`\; @R-buildmer].

To investigate if semantically informed perception had an influence on the ERPs within each phase of the experiment, we calculated pairwise comparisons contrasting the semantically informed condition against the naive condition within the pre-insight, insight, and post-insight phases.
This was done using the emmeans package [Version `r as.character(packageVersion("emmeans"))`\; @R-emmeans] and with Bonferroni correction for three separate tests.
All *p* values were computed by approximating the relevant denominator degrees of freedom using Satterthwaite's method as implemented in the lmerTest package [Version `r as.character(packageVersion("lmerTest"))`\; @R-lmerTest].

## Time-Frequency Analysis

For our exploratory analysis of event-related power, we first created new epochs from the ICA-corrected but unfiltered raw data.
Epochs that were marked as bad for the ERP analysis (i.e., with peak-to-peak amplitudes exceeding `r config$reject_peak_to_peak` µV) were also removed from the time-frequency analysis.
The remaining epochs were convolved with a family of Morlet wavelets, increasing linearly in their frequency from `r min(config$tfr_freqs)` Hz to `r max(config$tfr_freqs)` Hz in steps of `r config$tfr_freqs[2] - config$tfr_freqs[1]` Hz and in their width from `r min(config$tfr_cycles)` cycles to `r max(config$tfr_cycles)` cycles in steps of `r format(config$tfr_cycles[2] - config$tfr_cycles[1], digits = 1)` cycles.
To adjust for the typical $1/f$ shape of the EEG, the power values were transformed into percent signal change by first subtracting and then dividing by the average power at each frequency over the entire epoch [@grandchamp2011].
We then performed baseline correction by subtracting the average power during the pre-stimulus interval from -450 ms to -50 ms s relative to object onset.

For statistical analysis of event-related power, we conducted cluster-based permutation tests [@maris2007], separately for each of the three phases of the experiment (pre-insight, insight, and post-insight).
First, we averaged trials belonging to the same condition and then subtracted these average responses from one another to compute the difference between the semantically informed condition and the naive condition for each participant.
We then conducted one-sample $t$ tests in a mass-univariate fashion and grouped significant results (cluster-forming threshold $p < .05$) into clusters if they occurred at neighboring time points, frequencies, or channels.
Neighboring channels were defined using the Delaunay triangulation based on 2D electrode locations as implemented in MNE-Python.
To obtain family-wise error-corrected $p$ values at the cluster level, we compared the cluster mass (i.e., the sum of the $t$ values) of each observed cluster to an empirical null distribution of cluster masses obtained from 5,000 permutations with random sign flips.
Clusters were considered to be statistically significant if their mass exceeded the `r (1 - p_cluster) * 100`^th^ percentile of this distribution (i.e., cluster-level threshold $p < .05$, Bonferroni-corrected for three separate tests).

## Data and Code Accessibility

The EEG data are available upon reasonable request from the corresponding author because we had not asked participants for their consent to make the data publicly available.
The code for data analysis is available at [https://osf.io/uksbc/](https://osf.io/uksbc/).

In addition to the software mentioned above, our code relies on the tidyverse set of R packages [Version `r as.character(packageVersion("tidyverse"))`\; @R-tidyverse] for data wrangling, the ggplot2 [Version `r as.character(packageVersion("ggplot2"))`\; @R-ggplot2], cowplot [Version `r as.character(packageVersion("cowplot"))`\; @R-cowplot], and eegUtils [Version `r as.character(packageVersion("eegUtils"))`\; @R-eegUtils] packages for visualization, and the papaja package [Version `r as.character(packageVersion("papaja"))`\; @R-papaja] for statistical reporting.
We followed the workflow developed by @peikert2021 to ensure the long-term reproducibility of our analysis pipeline.

# Results

## Event-Related Potentials

Averaged across conditions, P1, N170, and N400 amplitudes differed as a function of the phase of the experiment (pre-insight, insight, or post-insight), all $F$s > `r min(filter(anova_table, effect == "phase")$f_value)`, all $p$s `r print_p(max(filter(anova_table, effect == "phase")$p_value))`.
In addition, N400 amplitudes differed as a function of the condition (semantically informed or naive), averaged across the three phases of the experiment, $F$(`r print_dof(filter(anova_table, component == "N400" & effect == "condition")$NumDF)`, `r print_dof(filter(anova_table, component == "N400" & effect == "condition")$DenDF)`) = `r filter(anova_table, component == "N400" & effect == "condition")$f_value`, $p$ `r print_p(filter(anova_table, component == "N400" & effect == "condition")$p_value)`.
Crucially, the phase × condition interaction was significant for all three ERP components, all $F$s > `r min(filter(anova_table, effect == "phase:condition")$f_value)`, all $p$s < `r print_p(max(filter(anova_table, effect == "phase:condition")$p_value))`.
To answer our main research question, we decomposed these interactions into pairwise comparisons of the semantically informed condition versus the naive condition within each of the three phases of the experiment.

In the pre-insight phase, when objects were unfamiliar to participants and presented without keywords, no differences emerged between the semantically informed condition and the naive condition in any of the the ERP components, all $|t|$s < `r max(abs(filter(contrast_table, phase == "Pre-insight")$t_value))`, all $p$s `r print_p(min(filter(contrast_table, phase == "Pre-insight")$p_value))` (Figure 1B--D).
This was expected given that the critical keywords (leading either to semantically informed perception or to naive perception) had not yet been presented, and given that the assignment of objects to conditions was counterbalanced across participants as to control for low-level visual differences.

In the insight phase, half of the unfamiliar objects were presented with matching keywords, leading to semantically informed perception, and the other half were presented with non-matching keywords, keeping the perception of the objects semantically naive.
Semantically informed perception in this phase was associated with enlarged (i.e., more negative) amplitudes in the N170 component, $b$ = `r filter(contrast_table, component == "N170" & phase == "Insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "N170" & phase == "Insight")$df)`) = `r filter(contrast_table, component == "N170" & phase == "Insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "N170" & phase == "Insight")$p_value)`, and reduced (i.e., less negative) amplitudes in the N400 component, $b$ = `r filter(contrast_table, component == "N400" & phase == "Insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "N400" & phase == "Insight")$df)`) = `r filter(contrast_table, component == "N400" & phase == "Insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table, component == "N400" & phase == "Insight")$p_value)`.
There was no reliable difference between conditions in the P1 component, $b$ = `r filter(contrast_table, component == "P1" & phase == "Insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "P1" & phase == "Insight")$df)`) = `r filter(contrast_table, component == "P1" & phase == "Insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "P1" & phase == "Insight")$p_value)`.

In the post-insight phase, the unfamiliar objects were presented for a third time and without any keywords, mirroring the pre-insight phase.
As in the insight phase, semantically informed perception was associated with reduced (i.e., less negative) amplitudes in the N400 component, $b$ = `r filter(contrast_table, component == "N400" & phase == "Post-insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "N400" & phase == "Post-insight")$df)`) = `r filter(contrast_table, component == "N400" & phase == "Post-insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table, component == "N400" & phase == "Post-insight")$p_value)`, while the effect in the N170 component did not recur, $b$ = `r filter(contrast_table, component == "N170" & phase == "Post-insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "N170" & phase == "Post-insight")$df)`) = `r filter(contrast_table, component == "N170" & phase == "Post-insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "N170" & phase == "Post-insight")$p_value)`.
Instead, the P1 component was significantly enlarged (i.e., more positive) in response to objects for which semantically informed perception had taken place, $b$ = `r filter(contrast_table, component == "P1" & phase == "Post-insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table, component == "P1" & phase == "Post-insight")$df)`) = `r filter(contrast_table, component == "P1" & phase == "Post-insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "P1" & phase == "Post-insight")$p_value)`.

## Event-Related Power

In an exploratory time-frequency analysis, we checked for differences in event-related power between semantically informed perception and naive perception within each of the three phases of the experiment.
Cluster-based permutation tests [@maris2007] revealed no significant clusters in the pre-insight phase (see Supplementary Figure 1), all $p$s > `r print_p(min(filter(tfr_clusters, contrast == "Pre-insight/Informed - Pre-insight/Naive")$p_val))`, but one significant cluster in the insight phase (see Figure 2), $p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Naive" & p_val < p_cluster)$p_val))`, and one significant cluster in the post-insight phase (see Figure 3), $p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Post-insight/Informed - Post-insight/Naive" & p_val < p_cluster)$p_val))`.
These two significant clusters in the insight and post-insight phases were similar in their direction, latency, frequency range, and topographic distribution.
Both clusters had a negative sign, started around 600 ms after object onset [but see @sassenhagen2019] and continued all the way until the end of the analyzed period at 1,400 ms.
They spanned a broad range of frequencies in the alpha and lower beta range as well as a broad set of channels, but appeared to be most focal at around 15 Hz and parietal channels.
Thus, semantically informed perception seems to alter not only early, evoked activity (see Event-Related Potentials above) but also later, induced activity, in the form of a reduction of post-stimulus power at parietal channels in the range of alpha and lower beta frequencies.

```{r, fig2, cache=!run$figures, fig.height=11, fig.cap="(ref:fig2-caption)"}
# Create topographic plots for event-related power in the insight phase
plot_tfr_topos(
  filter(tfr_grand_ave, phase == "Insight"),
  filter(tfr_clusters, contrast == "Insight/Informed - Insight/Naive"),
  p_cluster = p_cluster
)
```

(ref:fig2-caption) Time-frequency results for the insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
Black dots highlight EEG channels that were part of a cluster for which this difference was statistically significant ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Naive" & p_val < p_cluster)$p_val))`).

```{r, fig3, cache=!run$figures, fig.height=11, fig.cap="(ref:fig3-caption)"}
# Create topographic plots for event-related power in the post-insight phase
plot_tfr_topos(
  filter(tfr_grand_ave, phase == "Post-insight"),
  filter(
    tfr_clusters, contrast == "Post-insight/Informed - Post-insight/Naive"
  ),
  p_cluster = p_cluster
)
```

(ref:fig3-caption) Time-frequency results for the post-insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
Black dots highlight EEG channels that were part of a cluster for which this difference was statistically significant ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Post-insight/Informed - Post-insight/Naive" & p_val < p_cluster)$p_val))`).

## Control Analysis

```{r, control_analysis, include=FALSE}
# Filter relevant conditions for the control analysis
conditions_control <- c("Informed", "Exclude_informed")
trials %>%
  mutate(condition = factor(condition, levels = conditions_control)) %>%
  drop_na() -> trials_control

# Contrast coding for phase
cbind(
  c(`Pre-insight` = -1, `Insight` = 1, `Post-insight` = 0),
  c(`Pre-insight` = 0, `Insight` = -1, `Post-insight` = 1)
) %>%
  t() %>%
  ginv() -> contrasts(trials_control$phase)

# Contrast coding for condition
cbind(c(`Informed` = 1, `Exclude_informed` = -1)) %>%
  t() %>%
  ginv() -> contrasts(trials_control$condition)

# (Re-)do the actual model fitting if requested
if (run$control_analysis) {

  # Fit the model for each ERP component
  map(deps, fit_mixed_models, formula = form, data = trials_control) %>%
    set_names(deps) -> models_control

  # Fit an additional model for event-related power, controlling for RTs
  trials_main$alpha_beta <- trials_main$alpha_beta * 100 # Convert to percent
  form_rt <- ~ phase * condition + log(rt) +
    (phase * condition | participant_id) +
    (phase * condition | item_id)
  models_control$alpha_beta <-
    fit_mixed_models(form = form_rt, data = trials_main, dep = "alpha_beta")

  # Save models
  saveRDS(models_control, here(output_dir, "models_control.RDS"))
} else {

  # Read fitted models
  models_control <- readRDS(here(output_dir, "models_control.RDS"))
}

# Extract relevant statistics to print in the main text
map(models_control, function(mod) as_tibble(mod$contrasts)) %>%
  bind_rows(.id = "component") %>%
  rename(t_value = `t.ratio`, p_value = `p.value`) -> contrast_table_control
```

There are at least two alternative explanations for our finding that semantic information instantly affects early ERP responses.
First, differences in the P1 and/or N170 components might be driven by low-level visual differences between object images rather than by our experimental manipulation (matching versus non-matching keywords in the insight phase).
We ruled this out by counterbalancing the assignment of objects to conditions across participants, meaning that the same visual object entered the analysis in both conditions on an approximately equal number of trials, barring differences in participants' classification of the object and differences in the number of rejected EEG trials (see Materials and Methods).
Furthermore, we did not detect reliable differences between the two conditions in the pre-insight phase, that is, before any keywords had been presented.
It therefore seems unlikely that low-level differences could account for the effects of semantic information reported above.

Second, there is an alternative explanation specifically for the effects observed in the insight phase, when the objects were presented together with matching or non-matching keywords.
The N170 modulation might in fact not be due to semantic information changing the processing of objects in the semantically informed condition (as we had hypothesized), but rather a mismatch response to the objects in the naive condition.
The non-matching keywords might have primed participants to expect a certain set of visual features that did not actually come true once the object was displayed, potentially provoking a fast and strong brain response within the first 200 ms.
However, in a control analysis for this alternative explanation, we could show that the N170 effect in the insight phase does not depend on the naive condition.
For this control analysis, we contrasted the semantically informed condition (i.e., matching key words and participants indicating in their response that they knew what the object was or had an assumption) against a different control condition, namely, those objects that were presented with matching keywords (as in the semantically informed condition), but for which participants failed to capitalize on the keywords and instead indicated that they still did not know what kind of object they were viewing (a kind of "failed insight").
This was the case for an average of `r mean(objects_per_condition$Exclude_informed)` objects per participant (= `r percent(mean(objects_per_condition$Exclude_informed) / 60, accuracy = 0.1)` of objects presented with matching keywords).
Contrasting the semantically informed condition and the failed insight condition with matching key words, we again observed an enlarged (i.e., more negative) N170 component during semantically informed perception, $b$ = `r filter(contrast_table_control, component == "N170" & phase == "Insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table_control, component == "N170" & phase == "Insight")$df)`) = `r filter(contrast_table_control, component == "N170" & phase == "Insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table_control, component == "N170" & phase == "Insight")$p_value)`.
Likewise, the reduction of the N400 was replicated in this control analysis, $b$ = `r filter(contrast_table_control, component == "N400" & phase == "Insight")$estimate` µV, $t$(`r print_dof(filter(contrast_table_control, component == "N400" & phase == "Insight")$df)`) = `r filter(contrast_table_control, component == "N400" & phase == "Insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table_control, component == "N400" & phase == "Insight")$p_value)`, as was the late reduction in event-related power ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Exclude_informed" & p_val < p_cluster)$p_val))`; see Supplementary Figure 2).
This adds credibility to the notion that these effects are specific to those objects for which participants experienced a moment of insight induced by semantic information.

Finally, we had wondered if the reduction in alpha/beta power might merely reflect differences in the timing of motor preparation between conditions, given the well-established link between motor processes and beta power over sensorimotor cortex [@kilavik2013].
To rule this out, we extracted single trial percent signal change based on the distribution of clusters from the permutation tests (time window 600–1,200 ms, frequency range 8–20 Hz, electrodes P3, P4, Pz, PO3, PO4, and POz; see Figures 3 and 4).
We then subjected these to a linear-mixed effects model that controlled for log-transformed reaction time as a covariate of no interest.
This confirmed the significant reduction in alpha/beta power for the semantically informed condition as compared to the naive condition in the insight phase, $b$ = `r filter(contrast_table_control, component == "alpha_beta" & phase == "Insight")$estimate`%, $t$(`r print_dof(filter(contrast_table_control, component == "alpha_beta" & phase == "Insight")$df)`) = `r filter(contrast_table_control, component == "alpha_beta" & phase == "Insight")$t_value`, $p_\text{cluster}$ `r print_p(filter(contrast_table_control, component == "alpha_beta" & phase == "Insight")$p_value)`, as well as in the post-insight phase, $b$ = `r filter(contrast_table_control, component == "alpha_beta" & phase == "Post-insight")$estimate`%, $t$(`r print_dof(filter(contrast_table_control, component == "alpha_beta" & phase == "Post-insight")$df)`) = `r filter(contrast_table_control, component == "alpha_beta" & phase == "Post-insight")$t_value`, $p_\text{cluster}$ `r print_p(filter(contrast_table_control, component == "alpha_beta" & phase == "Post-insight")$p_value)`.

# Discussion

We found that providing participants with semantic information about previously unfamiliar objects instantly led to enlarged (i.e., more negative) ERP amplitudes in the N170 component and reduced (i.e., less negative) ERP amplitudes in the N400 component.
When the same objects were presented once more (without the semantic information), the N400 component remained reduced and the P1 component was now enlarged (i.e., more positive) in response to objects that had previously triggered semantically informed perception.
Finally, an exploratory time-frequency analysis revealed that semantically informed perception was accompanied by a late reduction in event-related power in the alpha and lower beta ranges.

The N400 effect during semantically informed perception indicates that acquiring an understanding of the objects lessened participants' demand for effortful semantic processing [@kutas2011].
It replicates previous work showing that N400 amplitudes are larger in response to pictures when they are either difficult to understand in and of themselves [e.g., @supp2005; @abdelrahman2008] or difficult to integrate into the preceding context [e.g., @barrett1990; @ganis1996; @hirschfeld2011].
The latency of this effect and the computational role of the N400 [@lau2008; @rabovsky2018; @bornkessel-schlesewsky2019] suggest a post-perceptual locus in the semantic system.

Our exploratory time-frequency analysis revealed a late (> 600 ms) reduction in post-stimulus power in the alpha and lower beta ranges (approx. 8--20 Hz).
While not predicted in advance, this is consistent with the finding that the dampening of oscillations in this range is associated with a facilitation in representing stimulus-specific information [@griffiths2019] and with successfully forming new semantic memories [@hanslmayr2009].
Like the N400 effect in the ERP, this reduction in power occurred as soon as participants had received the relevant semantic information and recurred once the same objects were re-encountered without any semantic information.

In contrast to the N400 and event-related power, the N170 component was modulated only on those initial trials on which the relevant semantic information was presented directly before the object.
It therefore constitutes an online marker of semantic insight, that is, of participants suddenly understanding the visual objects in the light of the information provided by the keywords.
The N170 is typically associated with the holistic perception of faces [@sagiv2001; @eimer2011] and other stimuli of visual expertise [@tanaka2001; @rossion2002].
It being enlarged during semantically informed perception may reflect that the semantic information made participants experience the configuration of the visual features of the objects in a new and meaningful way.
This interpretation is supported by previous findings of enlarged N170 amplitudes for scrambled (schematic) face stimuli after participants had been shown the original version of the face [@bentin2002], as well as for line drawings of meaningful objects as compared to non-objects [@beaucousin2011]. 
Together with the present study, these findings suggest an online impact of meaningfulness on the higher-level perception of visual objects, integrating across their visual features.

The P1 component, unlike the N400 and N170 components, was modulated by semantic information only one trial after this information had been obtained.
This is consistent with previous studies showing modulations of the P1 when participants had learned meaningful information about previously unfamiliar objects [@abdelrahman2008; @maier2018; @maier2019; @samaha2018; @weller2019].
What the present study adds is that the P1 effect does not take an extensive learning history to develop.
Instead, it can be observed as soon as one trial after semantic insight had happened.
Because the P1 is typically associated with lower-level sensory processing [@johannes1995; @pratt2011; @luck2014], we take its susceptibility to semantic information as an indicator that knowledge about the function of an object can change how we perceive its low-level features.

Both the N170 and the P1 components therefore seem to be sensitive to the semantic meaningfulness of visual objects.
The finding that these two components were modulated in different phases of our experimental design suggests that they reflect different aspects of top-down processing with different time courses and neuroanatomical implementations.
The time course of the N170 is consistent with a top-down influence of (non-visual) areas in the prefrontal and temporal-parietal cortices on visual areas, whereas modulations of the P1 component seem to reflect recurrent processing within the visual system [@wyatte2014].
Here we could show that the former pathway seems to be able to convey semantic information instantaneously (i.e., within the same trial), whereas the latter pathway seems to take at least one additional encounter with the visual object to emerge.
While the limited spatial resolution of the EEG precludes precise localization, there is converging fMRI evidence showing that semantic information can feed back into higher-level areas in the lateral occipital cortex (LOC) and early retinotopic cortex [areas V1, V2, and V3\; @hsieh2010], consistent with the neural generators of the N170 and P1 components in the ERP.

The top-down modulation of visual ERPs by semantic information challenges a modular view of visual perception [@fodor1983; @pylyshyn1999; but see @clarke2021].
Proponents of this view have pointed out important shortcomings of previous studies that had claimed to demonstrate top-down effects of cognition on perception [@firestone2016; @machery2015].
We addressed as many of these shortcomings as possible:
First, no difference between conditions had been present before any semantic information was presented.
Second, we used ERPs as an objective and time-resolved measure to disentangle perceptual and post-perceptual effects.
Third, we reduced response and demand biases by keeping the manipulation (i.e., matching or non-matching keywords) obscure to participants and by including well-known objects as filler stimuli.
Fourth, we precluded low-level visual differences between conditions by counterbalancing the assignment of objects to conditions across participants.
Fifth, we reduced priming and attentional effects by presenting all objects in a randomized order.
Sixth, we reduced memory effects by using only unfamiliar objects and by measuring online ERPs rather than delayed behavioral responses.
We hope that these measures were effective in ruling out many alternative explanations, thus making a compelling case against the "cognitive impenetrability" of visual perception.

A theoretical framework that would explicitly predict the observed P1 and N170 effects in our study is lacking at present.
However, the effects are consistent with the reverse hierarchy theory [@ahissar2004], which posits that objects first enter visual consciousness at an abstract, conceptual level. Once this initial "vision at a glance" has taken place, feedback connections to earlier layers of the visual system are being accessed to extract the relevant lower-level features ("vision with scrutiny").
This reverse trajectory down the visual hierarchy may explain (a) the semantically induced changes to the fMRI signal in LOC and retinotopic cortex [@hsieh2010] as well as (b) the modulations of early visual ERP components observed in the present study and others [e.g., @abdelrahman2008; @maier2014; @samaha2018].
An important role of top-down mechanisms for object recognition is also posited by theories of predictive coding and Bayesian inference [e.g., @yuille2006; @xu2007; @clark2013; @panichello2013; @lupyan2015].
Despite the theoretical advances, detailed descriptions of these top-down effects at the algorithmic and implementational levels remain a challenge for future work.

An interactive view of visual object processing with an abundance of top-down feedback also challenges the predominantly feed-forward models in computer vision [e.g., @marr1982; @serre2007; @krizhevsky2012; for review, see @lindsay2021].
The lack of semantic knowledge that dynamically interacts with the processing of visual features may be one key reason why even state-of-the-art deep-learning algorithms need orders of magnitude more training examples to achieve human-level performance in object recognition.
For these models, single-trial learning seems to be out of reach until the models overcome this "barrier of meaning" [@mitchell2020].
Drawing inspiration from neurocognitive data may help to make these models more biologically plausible and, at the same time, more data efficient [@maier2022].

Taken together, the present study provides preliminary evidence that whenever we receive meaningful semantic information about a previously unfamiliar object, this information has an immediate influence on our visual processing of this object.
The immediacy of this influence is remarkable in at least two different ways:
First, it does not require an extensive learning history but can instead be observed within the same trial in which the information has been presented and/or a single trial later.
Second, the time course of this influence suggests that it manifests itself not only at later, post-perceptual stages (> 400 ms), typically associated with semantic processing, but also at much earlier stages within the first 200 ms, associated with visual perception itself.

# References

\bigskip

<div id="refs" custom-style="Bibliography"></div>

\newpage
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}

# Supplementary Information

\bigskip

```{r tabs1, results="asis"}
# Print table of materials
read_csv(here("example_stimuli", "stimuli.csv")) %>%
  mutate(
    match_ger = paste0(
      "\\textit{", match_noun_ger, "}, \\textit{", match_verb_ger, "}"
    ),
    match_en = paste0("{[", match_noun_en, ", ", match_verb_en, "]}"),
    nonmatch_ger = paste0(
      "\\textit{", nonmatch_noun_ger, "}, \\textit{", nonmatch_verb_ger, "}"
    ),
    nonmatch_en = paste0("{[", nonmatch_noun_en, ", ", nonmatch_verb_en, "]}"),
  ) %>%
  transmute(
    img = paste0(
      "\\includegraphics[valign=c,scale=0.25]{example_stimuli/",
      item_id,
      ".png}"
    ),
    match = paste(match_ger, match_en, sep = "\n") %>%
      kableExtra::linebreak(align = "l", linebreaker = "\n"),
    nonmatch = paste(nonmatch_ger, nonmatch_en, sep = "\n") %>%
      kableExtra::linebreak(align = "l", linebreaker = "\n")
  ) %>%
  apa_table(
    booktabs = TRUE,
    col.names = c(
      "Object", "Matching keywords", "Non-matching keywords"
    ),
    escape = FALSE,
    longtable = TRUE,
    caption = "Example stimuli\\smallskip",
    font_size = "footnotesize"
  )
```

\newpage

## Results S1. *Linear Mixed-Effects Models*

## *P1 Component (100--150 ms)*

\small
\singlespacing

```{r, ress1a}
# Helper function for printing model summary, ANOVA (F tests), and contrasts
print_model_outputs <- function(model_object) {
  model_object$summary$call$data <- NULL # Prevents cluttering the output
  print(model_object$summary)
  cat("\n")
  print(model_object$anova)
  cat("\nPairwise Contrasts (Simple Effects)\n")
  print(model_object$contrasts)
  cat("\n\n")
}

# Print model outputs
print_model_outputs(models$P1)
```

\newpage
\normalsize
\doublespacing

## *N170 Component (150--200 ms)*

\small
\singlespacing

```{r, ress1b}
# Print model outputs
print_model_outputs(models$N170)
```

\newpage
\normalsize
\doublespacing

## *N400 Component (400--700 ms)*

\small
\singlespacing

```{r, ress1c}
# Print model outputs
print_model_outputs(models$N400)
```

\newpage

```{r, figs1, cache=!run$figures, fig.height=11, fig.cap="(ref:figs1-caption)"}
# Create topographic plots for event-related power in the pre-insight phase
plot_tfr_topos(
  filter(tfr_grand_ave, phase == "Pre-insight"),
  filter(tfr_clusters, contrast == "Pre-insight/Informed - Pre-insight/Naive"),
  p_cluster = p_cluster
)
```

(ref:figs1-caption) Time-frequency results for the pre-insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
A cluster-based permutation test indicated no clusters for which this difference was statistically significant (all $p$s > `r print_p(min(filter(tfr_clusters, contrast == "Pre-insight/Informed - Pre-insight/Naive")$p_val))`).

```{r, figs2, cache=!run$figures, fig.height=11, fig.cap="(ref:figs2-caption)"}
# Create topographic plots for control analysis of event-related power
plot_tfr_topos(
  filter(tfr_grand_ave, phase == "Insight"),
  filter(
    tfr_clusters, contrast == "Insight/Informed - Insight/Exclude_informed"
  ),
  p_cluster = p_cluster,
  condition_plus = "Informed",
  condition_minus = "Exclude_informed",
  title_conditions = "Informed - failed"
)
```

(ref:figs2-caption) Time-frequency results for the control analysis.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the "failed insight" condition (see Results: Control Analysis in the main text), grand-averaged across participants.
Black dots highlight EEG channels that were part of a cluster for which this difference was statistically significant ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Exclude_informed" & p_val < p_cluster)$p_val))`).
