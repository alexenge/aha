---
title             : "Instant effects of semantic information on visual perception"
shorttitle        : "Semantically informed perception"

author: 
  - name          : "Alexander Enge"
    affiliation   : "1,2"
    corresponding : "yes"
    address       : "Rudower Chaussee 18, 12489 Berlin, Germany"
    email         : "alexander.enge@hu-berlin.de"
  - name          : "Franziska Süß"
    affiliation   : "3"
  - name          : "Rasha Abdel Rahman"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Humboldt-Universität zu Berlin"
  - id            : "2"
    institution   : "Research Group Learning in Early Childhood, Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig"
  - id            : "3"
    institution   : "Fachhochschule des Mittelstands, Bamberg"

authornote: |
  Alexander Enge \orcidlink{0000-0003-0100-2297} [https://orcid.org/0000-0003-0100-2297](0000-0003-0100-2297)
  
  Rasha Abdel Rahman \orcidlink{0000-0002-8438-1570} [https://orcid.org/0000-0002-8438-1570](0000-0002-8438-1570)
  
  The authors declare no competing financial interests.
  The materials and code for this study are available at [https://osf.io/uksbc](https://osf.io/uksbc).

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

bibliography      : ["manuscript_files/references.bib", "manuscript_files/r-references.bib"]
csl               : "manuscript_files/citation_style.csl"

documentclass     : "apa6"
classoption       : "man,donotrepeattitle"
fontsize          : "10pt"

editor_options: 
  chunk_output_type: console
  
output:
  papaja::apa6_pdf:
    latex_engine: xelatex

header-includes:
  - \geometry{a4paper}
  - \raggedbottom
  - \usepackage{orcidlink}
  - \usepackage[all]{nowidow}
  - \captionsetup[figure]{belowskip=10pt}
  - \captionsetup[figure]{font={small,stretch=1},textfont=normalfont}
  - \captionsetup[figure]{labelfont=bf,labelsep=period,name=Figure}
  - \captionsetup[table]{labelfont=bf,labelsep=period,textfont=bf}
  - \usepackage[export]{adjustbox}
  - \usepackage{makecell}
  - \usepackage{setspace}
---

```{r, setup, include=FALSE}
# Load R packages
library(buildmer)
library(emmeans)
library(here)
library(knitr)
library(lmerTest)
library(MASS)
library(scales)
library(papaja)
library(cowplot)
library(parallel)
library(reticulate)
library(tidyverse)
library(magrittr)

# Set global options
options(readr.show_col_types = FALSE)
opts_chunk$set(
  fig.width = 12,
  include = FALSE,
  message = FALSE,
  out.width = "100%",
  warning = FALSE
)

# Specify directory paths
data_dir <- here("data")
files_dir <- here("manuscript_files")
output_dir <- here("output")
report_dir <- here("output/qc_reports")

# Load custom helper functions for creating figures and tables
source(here(files_dir, "helper_functions.R"))

# Re-run steps that take a long time to compute?
run <- list(
  eeg_processing = TRUE,
  mixed_models = TRUE
)

# Write R packages to bibliography
r_refs(here(files_dir, "r-references.bib"), append = FALSE)
```

# Abstract

Does our perception of an object change as soon as we discover what function it serves?
This question matters not only when we encounter novel tools or gadgets in our everyday lives, but also pertains to the long-standing debate around the (im)penetrability of perception by higher cognitive capacities.
Here, we showed human participants (*n* = 48) pictures of unfamiliar objects either together with words matching their function, leading to semantically informed perception, or together with non-matching words, resulting in naive perception.
We measured event-related potentials (ERPs) to investigate at which stages in the visual processing hierarchy these two types of object perception differed from one another.
We found that semantically informed as compared to naive perception was associated with larger amplitudes in the N170 component (150--200 ms) and reduced amplitudes in the N400 component (400--700 ms).
When the same objects were presented once more without any information, the N400 effect persisted and we also observed enlarged amplitudes in the P1 component (100--150 ms) in response to objects for which semantically informed perception had taken place.
Consistent with previous work, our results suggest that obtaining semantic information about previously unfamiliar objects alters aspects of their lower-level visual perception (P1 component), higher-level visual perception (N170 component), and semantic processing (N400 component).
We demonstrate for the first time that these effects are instantaneous in the sense that they can be observed within the same trial as well as one trial after the information has been given, providing strong evidence that cognition affects perception.

*Key words*: objects; semantic knowledge; visual perception; event-related potentials

\bigskip

# Significance Statement

There has been a long-standing debate about whether or not higher-level cognitive capacities such as semantic knowledge can influence lower-level perceptual processing in a top-down fashion.
Here we could show for the first time that information about the function of previously unfamiliar objects immediately influences cortical processing within less than 200 ms.
Of note, this influence does not require training or experience with the objects and related semantic information.
Therefore, our study is the first to show effects of cognition on perception while ruling out the possibility that prior knowledge merely acts by pre-activating or altering stored visual representations.
Instead, this knowledge seems to alter perception online, thus providing a compelling case against the cognitive impenetrability of perception by cognition.

\newpage

# Introduction

Does our perception of an object change as soon as we discover what function it serves?
This question speaks not only to our everyday experiences, where we encounter novel tools and gadgets in our dynamic working and private environments.
It also pertains to the long-standing debate about the cognitive (im)penetrability [@pylyshyn1999] of perception by higher-level capacities such as semantic knowledge or language.
According to one view, these cognitive capacities kick in only after the retinal input has been processed by a specialized module for visual perception [@firestone2016; @fodor1983].
This module is encapsulated from higher-level inputs and therefore processes the visual information in a purely feedforward fashion, progressing from lower areas with small receptive field sizes to areas representing increasingly complex shapes and, eventually, whole objects [@dicarlo2012].
This architecture has been mirrored in classical [e.g., @marr1982] and contemporary [e.g., @krizhevsky2012] computer vision models, allowing them to achieve human-level perfomance in predicting object category labels from images [for review, see @lindsay2020].

The cognitive impenetrability hypothesis is challenged by the alternative view that perception dynamically interacts with different aspects of cognition from early on [@churchland1994; @lupyan2015].
This view is supported by a variety of theoretical, behavioral, and neurophysiological accounts.
On the theoretical level, the reverse hierarchy theory [@ahissar2004; @hochstein2002] posits that conscious processing initally occurs at the level of whole objects or object categories.
Only after this high-level interpretation has been obtained, more fine grained visual details---if relevant for the current task---are being accessed via top-down connections.
Along similar lines, Bayesian inference and predictive coding theories [e.g., @clark2013; @panichello2013; @yuille2006] propose bi-directional loops of predictions and prediction errors between visual and non-visual processes.

On the behavioral level, these ideas are supported by psychological studies that showed differences in ratings, detection rates, or reaction times for visual stimuli depending on their emotional [e.g., @phelps2016], motivational [e.g., @balcetis2010], linguistic [e.g., @boutonnet2015] or semantic [e.g., @gauthier2003] background.
However, some of these studies confounded tentantive high-level effects with low-level differences between conditions.
Furthermore, many studies were not able to discern between perceptual and post-perceptual (e.g., memory-related) effects [@firestone2016].

On the neurophysiological level, event-related potentials (ERPs) measured from the human EEG can mitigate most of these concerns:
Their excellent temporal resolution allows us to probe how early we can detect influences of high-level (e.g., semantic) information.
To this end, participants were typically trained to associate visual objects with different amounts of semantic information.
After training, an orthogonal task was used to compare the ERPs in response to semantically trained objects versus non-semantically trained objects.
This revealed differences not only in late ERP components associated with semantic processing (i.e., the N400 component) but also in the visual P1 component [@abdelrahman2008; @maier2019; @samaha2018; @weller2019].
The early peak of this component and its source in the occipital cortex [@abdelrahman2008] point to an immediate effect of semantic knowledge on visual perception.

Here we measured ERPs in response to unfamiliar objects instantly while participants gained an semantic understanding of their function.
To this end, we presented half of the objects together with matching keywords, thus allowing participants to understand what kind of object they were viweing, or together with non-matching keywords, thus keeping the perception of the object semantically naive.
We then presented the same objects again to test for downstream effects of semantic information as in previous studies.
We examined the influence of semantic information on ERPs associated with lower-level visual perception (P1 component), higher-level visual perception (N170 component), and semantic processing (N400 component).
We hypothesized that semantic information would have instant effects on visual perception, by which we mean (a) that these effects can already be observed on the same trial as the semantic information is being presented for the first time, and (b) that these effects are found not only in later, higher-level cognition-related ERP components (i.e., N400), but also in earlier, perception-related ERP components (i.e., P1 and/or N170).
We furthermore conducted an exploratory time-frequency analysis to test if event-related power also showed instant effects of semantic information.
This was to make sure that we would also capture any non-phase-locked, putatively oscillatory activity related to semantically informed perception.

# Materials and Methods

## Participants

Participants were 48 German native speakers (31 female, 17 male) with a mean age of 23.5 years (range 18--32) and no history of psychological disorder or treatment.
No a priori power analysis was carried out and the sample size was chosen in line with previous EEG studies on object processing in our lab.
All participants were right-handed according to the Edinburgh inventory [@oldfield1971] and reported normal or corrected-to-normal vision.
They provided written informed consent before starting the experiment and received a compensation of €8 per hour for participating.

## Stimuli

Stimuli consisted of 240 grayscale photographs of real-world objects.
Of these, 120 were well-known everyday objects (e.g., a bicycle, a toothbrush) and served as filler stimuli of no interest.
The other 120 were rare objects presumed to be unfamiliar to the majority of participants (e.g., a galvanometer, an udu drum; see Appendix A).
All stimuli were presented on a light blue background with a size of 207 × 207 pixels on a 19-inch LCD monitor with a resolution of 1,280 × 1,024 pixels and a refresh rate of 75 Hz.
At a standardized viewing distance of 90 cm, the images subtended approximately 3.9 degrees of participants' horizontal and vertical visual angle.

For each unfamiliar object, a pair of German keywords (a noun and a verb) was selected, describing the typical function or use of the object in a way that could typically be related to its visual features and their configuration (e.g., voltage--measuring; clay pot--drumming).
As our central experimental manipulation, the presentation of half of the objects was preceded by keywords that correctly matched their respective function, whereas the presentation of the other half of the objects was preceded by non-matching keywords belonging to one of the other objects.
The matching keywords were expected to induce semantically informed perception (i.e., participants suddenly understanding what kind of object they were viewing), whereas the non-matching keywords were expected to prevent such an understanding and keep the perception of the object semantically naive.
All participants saw each unfamiliar object with only one type of keywords (matching or non-matching).
This assignment of keywords to objects was counterbalanced across participants so that each object was presented with matching keywords (leading to semantically informed perception) and non-matching keywords (leading to naive perception) to an equal number of participants.
The experiment was programmed and displayed using Presentation® software (Neurobehavioral Systems, Inc., Berkeley, CA, www.neurobs.com).

## Experimental Design

The experiment consisted of three phases (see Figure \@ref(fig:fig1)A).
In the *pre-insight* phase, after written informed consent had been obtained and the EEG had been prepared, all 240 familiar and unfamiliar objects were presented once in random order and without any keywords.
Each trial consisted of a fixation cross presented in the middle of the screen for 0.5 s, followed by the presentation of the object until participants made a response or until a time out after 3 s.
The inter-trial interval was 0.5 s and participants took a self-timed break after each block of 60 objects.
The task, which was kept the same across all three phases, was to classify each object using one of four response alternatives: (a) "I know what this is or have a strong assumption," (b) "I have an assumption what this is," (c) "I have rather no assumption what this is," or (d) "I don't know what this is and have no assumption." Participants were asked to respond as quickly and as accurately as possible by pressing one out of four buttons with the index or middle finger of their left or right hand, respectively.
The mapping of the rating scale to the four buttons (left to right or right to left) was counterbalanced across participants.

```{r, eeg_processing}
# Define function for processing behavioral log files
read_log <- function(log_file) {

  # Read the file
  read_tsv(
    log_file,
    col_types = cols(),
    locale = locale(encoding = "latin1")
  ) %>%
    # Recode some columns
    transmute(

      # Phase of the experiment
      phase = factor(Wdh,
        levels = c(211, 212, 213),
        labels = c("Pre-insight", "Insight", "Post-insight")
      ),

      # Keyword conditions
      keywords = factor(Bed,
        levels = c("richtig", "falsch"),
        labels = c("Match", "Non-match")
      ),

      # Behavioral responses
      # 201: "I know what this is or have a strong assumption"  -> Recode as 4
      # 202: "I have an assumption what this is"                -> Recode as 3
      # 203: "I have rather no assumption what this is"         -> Recode as 2
      # 204: "I don't know what this is and have no assumption" -> Recode as 1
      response = 5 - (Tastencode - 200),

      # Reaction times
      rt = RT,

      # Item IDs
      item_id = factor(StimID)
    ) %>%
    # Remove filler items
    drop_na(keywords) -> log

  # Assign items to conditions based on manipulation (matching vs. non-
  # matching keywords) and the responses of the participants
  items_per_condition <- with(log, {
    list(

      # Informed condition: Matching keywords and positive response
      "Informed" = item_id[
        phase == "Insight" & keywords == "Match" & response %in% c(3, 4)
      ],

      # Naive condition: Non-matching keywords and negative response
      "Naive" = item_id[
        phase == "Insight" & keywords == "Non-match" & response %in% c(1, 2)
      ],

      # Exclude: Matching keywords and negative response
      "Exclude_informed" = item_id[
        phase == "Insight" & keywords == "Match" & response %in% c(1, 2)
      ],

      # Exclude: Non-matching keywords and positive response
      "Exclude_naive" = item_id[
        phase == "Insight" & keywords == "Non-match" & response %in% c(3, 4)
      ],

      # Exclude: Positive response *before* any info was presented
      "Exclude_known" = item_id[phase == "Pre-insight" & response == 4]
    )
  })

  # Assign these conditions to the trials of all three phases
  log$condition <- NA
  for (condition in names(items_per_condition)) {
    item_id <- items_per_condition[[condition]]
    log$condition[log$item_id %in% item_id] <- condition
  }

  # Sort columns
  log %>%
    select(item_id, phase, condition, response, rt)
}

# Get list of behavioral log files
log_files <- c(
  list.files(here(data_dir, "rt/exp1"), "*.txt", full.names = TRUE),
  list.files(here(data_dir, "rt/exp2"), "*.txt", full.names = TRUE)
)

# Get list of BrainVision EEG header files
vhdr_files <- c(
  list.files(here(data_dir, "eeg/exp1"), "*.vhdr", full.names = TRUE),
  list.files(here(data_dir, "eeg/exp2"), "*.vhdr", full.names = TRUE)
)

# Import EEG pipeline from Python
pipeline <- import("pipeline")

# Extract versions of Python packages
pipeline_version <- pipeline$`__version__`
mne_version <- import("mne")$`__version__`

# Do the actual preprocessing if requested
if (run$eeg_processing) {

  # Process behavioral data
  logs <- map(log_files, read_log)

  # Process EEG data
  res <- pipeline$group_pipeline(
    vhdr_files = vhdr_files,
    log_files = logs,
    output_dir = output_dir,
    epochs_dir = here(output_dir, "epochs"),
    report_dir = report_dir,
    downsample_sfreq = 125.0,
    bad_channels = NULL,
    ica_method = "fastica",
    ica_n_components = 0.99,
    highpass_freq = 0.1,
    lowpass_freq = 30.0,
    triggers = c(221, 222),
    epochs_tmin = -0.5,
    epochs_tmax = 1.5,
    baseline_tmin = -0.2,
    baseline_tmax = 0.0,
    reject_peak_to_peak = 150.0,
    components = list(
      "name" = list("P1", "N170", "N400"),
      "tmin" = list(0.1, 0.15, 0.4),
      "tmax" = list(0.15, 0.2, 0.7),
      "roi" = list(
        c("PO3", "PO4", "POz", "O1", "O2", "Oz"),
        c("P7", "P8", "PO7", "PO8", "PO9", "PO10"),
        c("C1", "C2", "Cz", "CP1", "CP2", "CPz")
      )
    ),
    average_by = c("phase/condition"),
    perform_tfr = TRUE,
    tfr_subtract_evoked = FALSE,
    tfr_freqs = seq(4, 40, by = 1.0),
    tfr_cycles = seq(2, 20, by = 0.5),
    tfr_baseline_tmin = -0.45,
    tfr_baseline_tmax = -0.05,
    tfr_baseline_mode = "percent",
    perm_contrasts = list(
      c("Pre-insight/Informed", "Pre-insight/Naive"),
      c("Insight/Informed", "Insight/Naive"),
      c("Post-insight/Informed", "Post-insight/Naive")
    ),
    perm_tmin = 0.0,
    perm_tmax = 1.0,
    n_jobs = 1
  )
}

# Read single trial data
read_csv(here(output_dir, "trials.csv"), col_types = cols(
  participant_id = col_factor(),
  item_id = col_factor(),
  phase = col_factor(),
  condition = col_factor()
)) %>%
  # Mark unrealistically short RTs
  mutate(rt = ifelse(rt < 200, NA, rt)) -> trials

# Compute number of objects per condition for each participant
with(trials, table(participant_id, condition)) %>%
  `/`(3) %>%
  as.data.frame.matrix() %>%
  rownames_to_column("subject_id") -> objects_per_condition

# Read by-participant ERP averages and channel locations
evokeds <- read_csv(here(output_dir, "ave.csv"))

# Read pipeline configuration
config <- jsonlite::read_json(
  here(output_dir, "config.json"),
  simplifyVector = TRUE, simplifyMatrix = FALSE
)

# Count number of rejected epochs per participant
rejected_epochs <- lengths(config$auto_rejected_epochs)

# Read channel locations
channel_locations <- read_csv(here(output_dir, "channel_locations.csv"))

# Read grand-averaged power
tfr_grand_ave <- read_csv(here(output_dir, "tfr_grand_ave.csv"))

# Read results of cluster-based permutation tests for ERPs
clusters <- read_csv(here(output_dir, "clusters.csv"))

# Read results of cluster-based permutation tests for TFR
tfr_clusters <- read_csv(here(output_dir, "tfr_clusters.csv"))
```

```{r, mixed_models, eval=run$mixed_models}
# Filter relevant conditions for the main analysis
trials %>%
  mutate(condition = factor(condition, levels = c("Informed", "Naive"))) %>%
  drop_na() -> trials_main

# Contrast coding for phase
cbind(
  c("Pre-insight" = -1, "Insight" = 1, "Post-insight" = 0),
  c("Pre-insight" = 0, "Insight" = -1, "Post-insight" = 1)
) %>%
  t() %>%
  ginv() -> contrasts(trials_main$phase)

# Contrast coding for condition
cbind(c("Informed" = 1, "Naive" = -1)) %>%
  t() %>%
  ginv() -> contrasts(trials_main$condition)

# Construct model formula
form <- ~ phase * condition +
  (phase * condition | participant_id) +
  (phase * condition | item_id)

# Fit linear mixed models
deps <- c("P1", "N170", "N400")
map(deps, function(dep, model_formula = form, model_data = trials_main) {

  # Modify the formula such that fixed effects are always retained
  model_formula %<>%
    tabulate.formula() %>%
    mutate(block = replace(block, is.na(grouping), "fixed"))

  # Start a CPU cluster so that multiple models can be fitted in parallel
  n_cores <- detectCores()
  cl <- makeCluster(n_cores)

  # Find the best fitting model (see Matuschek et al., 2017, *JML*)
  build <- buildmer(
    buildmerControl = buildmerControl(
      formula = model_formula,
      data = model_data,
      args = list("control" = lme4::lmerControl(
        optimizer = "bobyqa", optCtrl = list(maxfun = 1e6)
      )),
      direction = c("backward", "backward"),
      cl = cl,
      elim = LRTalpha(.20),
      calc.anova = TRUE,
      ddf = "Satterthwaite",
      dep = dep
    )
  )
  stopCluster(cl)

  # Compute marginal means and contrasts
  emm_options(lmer.df = "Satterthwaite", lmerTest.limit = Inf)
  specs <- pairwise ~ condition | phase
  means <- emmeans(build@model, specs = c("phase", "condition"))
  contrasts <- contrast(means, "pairwise", simple = "condition") %>%
    summary(by = NULL, adjust = "bonferroni")

  # Create list of returns
  list(
    "model" = build@model,
    "summary" = build@summary,
    "anova" = build@anova,
    "means" = means,
    "contrasts" = contrasts
  ) %>%
    return()
}) %>%
  # Add ERP component names
  set_names(deps) -> models

# Save models
saveRDS(models, here(output_dir, "models.RDS"))
```

```{r, fig1, include=TRUE, fig.height=12, fig.cap="(ref:figure-1-caption)"}
# Read fitted models
models <- readRDS(here(output_dir, "models.RDS"))

# Extract relevant statistics to print in the main text
map(models, function(model) as_tibble(model$anova, rownames = "effect")) %>%
  bind_rows(.id = "component") %>%
  rename(f_value = `F value`, p_value = `Pr(>F)`) -> anova_table
map(models, function(model) as_tibble(model$contrasts)) %>%
  bind_rows(.id = "component") %>%
  rename(t_value = `t.ratio`, p_value = `p.value`) -> contrast_table

# Create Figure 1
plot_fig1(files_dir, evokeds, config, channel_locations, models)
```

(ref:figure-1-caption) Experimental design and ERP results.
***A***, In the pre-insight phase, participants were presented with 120 unfamiliar objects and indicated whether they knew what kind of object they were viewing.
In the insight phase, half of these objects were presented with matching keywords (in purple color for illustration), leading to semantically informed perception, and the other half with non-matching keywords (in green color for illustration), leading to naive perception.
In the post-insight phase, the same objects were presented again without keywords.
***B***, ***C***, ***D***, ERP waveforms and scalp topographies of the P1 component (100--150 ms, ***B***), of the N170 component (150--200 ms, ***C***), and of the N400 component (400--700 ms, ***D***) are shown for objects with semantically informed perception versus naive perception within the three different phases.
Semantically informed perception was associated with more negative amplitudes in the N170 component during the insight phase, less negative amplitudes in the N400 component during the insight and post-insight phases, and more positive amplitudes in the P1 component during the post-insight phase.
The time windows and channels for quantifying the different ERP components are highlighted by the gray areas in the ERP waveforms and by the white markers on the scalp topographies, respectively.
Colored ribbons around the ERP waveforms show ± 1 standard error of the mean across participants.
Ampl. = amplitude.\newline
\* *p* $<$ .05. \*\* *p* $<$ .01. \*\*\* *p* $<$ .001.

In the *insight* phase, the 120 unfamiliar objects were presented for the second time, now preceded either by matching keywords (leading to semantically informed perception) or by non-matching keywords (leading to naive perception).
Each trial consisted of a fixation cross presented for 0.5 s, followed by the presentation of the keywords for 2.5 s.
Then, an asterisk was presented in the middle of the screen for another 0.5 s, followed by the presentation of the object until a response was made or until a time out after 3 s.
The objects were presented in blocks of 30 trials so that within each block (a) there were 15 objects from each of the two experimental conditions and (b) objects were heterogeneous in terms of their shape, visual complexity, and functional category (e.g., medical devices, musical instruments).

In the *post-insight* phase, the unfamiliar objects were presented for a third time with the same trial structure as in the pre-insight phase, that is, without any keywords.
The insight and post-insight phases were presented in an interleaved fashion so that after the presentation of one block of 30 objects in the insight phase (with keywords), participants took a self-timed break and continued with the same block of 30 objects in the post-insight phase (without keywords) before moving on to the next block consisting of 30 different objects.
They continued like this until all four blocks were completed in both phases.
In total, the experiment consisted of 480 trials (120 familiar objects in the pre-insight phase and 120 unfamiliar objects in the pre-insight, insight, and post-insight phases).
It took participants approximately 35 minutes to complete.

## Behavioral Data Analysis

We first excluded from all further analyses those objects for which the participant had responded with "I know what this is" in the pre-insight phase (i.e., before any keywords were presented).
This led to the exclusion of an average of `r mean(objects_per_condition$Exclude_known)` objects per participant (= `r percent(mean(objects_per_condition$Exclude_known) / 120, accuracy = 0.1)` of all unfamiliar objects).
Next, to delineate semantically informed and naive perception, the assignment of the remaining objects to one of these two conditions was co-determined by our experimental manipulation (matching versus non-matching keywords) and the behavioral responses of the participant in the insight phase (see Figure \@ref(fig:fig1)A).
Objects were assigned to the semantically informed condition if they were presented with matching keywords *and* if the participant indicated knowing what the object was or having an assumption.
This was the case for an average of `r mean(objects_per_condition$Informed)` objects per participant (= `r percent(mean(objects_per_condition$Informed) / 60, accuracy = 0.1)` of objects presented with matching keywords).
Complementarily, objects were assigned to the naive condition if they were presented with non-matching keywords *and* if the participant indicated not knowing what the object was or having rather no assumption.
This was the case for an average of `r mean(objects_per_condition$Naive)` objects per participant (= `r percent(mean(objects_per_condition$Naive) / 60, accuracy = 0.1)` of objects presented with non-matching keywords).
The same assignment of objects to conditions, based on the manipulation and responses in the insight phase, was also used for analyzing the pre-insight and post-insight phases.
This allowed us to test, on the one hand, if the objects from both conditions differed in important aspects even before any keywords were presented (pre-insight phase) and, on the other hand, if the semantic understanding acquired in the insight phase had any down-stream effects on the subsequent perception of the objects (post-insight phase).

## EEG Recording and Preprocessing

The continuous EEG was recorded from 62 Ag/AgCl scalp electrodes placed according to the extended 10--20 system [@americanelectroencephalographicsociety1991] and referenced online to an external electrode placed on the left mastoid (M1).
Two additional external electrodes were placed on the right mastoid (M2) and below the left eye (IO1), respectively.
Electrode impedances were kept below 5 kΩ.
An online band-pass filter with a high-pass time-constant of 10 s (0.016 Hz) and a low-pass cutoff frequency of 1000 Hz was applied before digitizing the signal at a sampling rate of 500 Hz.

The data were preprocessed offline using custom scripts, available online in the hu-neuro-pipeline package (Version `r pipeline_version`; https://github.com/alexenge/hu-neuro-pipeline) and based on the MNE-Python software [Version `r mne_version`\; @gramfort2013] in Python [Version `r py_version()`\; @vanrossum2009].
First, the data were were downsampled to `r config$downsample_sfreq` Hz and re-referenced to the common average of all scalp channels.
Next, artifacts resulting from blinks and eye movements were removed via independent component analysis (ICA) on a low-pass filtered copy of the data (cutoff = 1 Hz).
A variable number of components per participants were extracted from an initial principal component analysis (PCA) so that they explained at least `r percent(config$ica_n_components)` of the variance in the data (mean = `r mean(unlist(config$auto_ica_n_components))` components, range `r min(unlist(config$auto_ica_n_components))`--`r max(unlist(config$auto_ica_n_components))`).
Then the ICA was fitted using the FastICA algorithm [@hyvarinen1999].
Any independent components showing significant correlations with either of two virtual EOG channels (VEOG: IO1 - Fp1, HEOG: F9 - F10) were removed automatically using the MNE-Python's `find_bads_eog` method.
This was the case for an average of `r mean(lengths(config$auto_ica_bad_components))` components per participant (range = `r min(lengths(config$auto_ica_bad_components))`--`r max(lengths(config$auto_ica_bad_components))`)

## Event-Related Potential Analysis

For the analysis of ERP voltages, a zero-phase, non-causal FIR filter with a lower pass-band edge at `r config$highpass_freq` Hz (transition bandwidth: 0.1 Hz) and an upper pass-band edge at `r config$lowpass_freq` Hz (transition bandwidth: 7.5 Hz) was applied.
Next, the continuous EEG was segmented into epochs ranging from `r config$epochs_tmin` s to `r config$epochs_tmax` s relative the onset of the presentation of each unfamiliar object.
These epochs were baseline-corrected by subtracting the average voltage during the interval of `r config$baseline_tmin` s to `r config$baseline_tmax` s relative to stimulus onset.
Epochs containing artifacts despite ICA, defined as peak-to-peak amplitudes exceeding `r config$reject_peak_to_peak` µV, were removed from further analysis.
This led to the exclusion of an average of `r mean(rejected_epochs)` trials per participant (= `r percent(mean(rejected_epochs) / 360, accuracy = 0.1)`; range `r min(rejected_epochs)`--`r max(rejected_epochs)` trials).
Single-trial event-related potentials were computed as the mean amplitude across time windows and regions of interests (ROIs) defined a priori, namely 100--150 ms at electrodes PO3, POz, PO4, O1, Oz, and O2 and for the P1 component, 150--200 ms at electrodes P7, P8, PO7, PO8, PO9, and PO10 for the N170 component, and 400--700 ms at electrodes C1, Cz, C2, CP1, CPz, and CP2 for the N400 component.

The resulting mean ERP amplitudes were analyzed on the single-trial level using linear mixed-effects regression models because they allow controlling for repeated measures of participants and stimuli while also being robust against unbalanced numbers of trials per condition [@baayen2008; @burki2018; @fromer2018].

We computed three models predicting P1, N170, and N400 amplitudes, respectively.
All models included three fixed effects: (a) the phase of the experiment, coded as a repeated contrast [i.e., subtracting the first phase from the second phase and the second phase from the third phase, the intercept being the grand mean across all three phases\; @schad2020], (b) the condition of the object, coded as a scaled sum contrast (i.e., subtracting the naive condition from the semantically informed condition, the intercept being the grand mean across both conditions), and (c) the two-way interaction of phase and condition.
We determined the most parsimonous random effect structure supported by the data using the automatic procedure proposed by @matuschek2017.
This involved starting with a maximal model that contained all random parameters (intercepts, slopes, and correlations) and then iteratively removing terms as long as this did not result in a significant drop in model fit (likelihood ratio test, $p$ value cutoff = .20).
See Supplementary Results 1 for the final model syntax and model outputs.
All models were fitted in R [Version `r as.character(packageVersion("base"))`\; @R-base] using the lme4 package [Version `r as.character(packageVersion("lme4"))`\; @R-lme4] with the optimizer function *bobyqa* and a maximum of 10^6^ iterations for maximum likelihood estimation.
The model selection algorithm via likelihood ratio tests was performed using the buildmer package [Version `r as.character(packageVersion("buildmer"))`\; @R-buildmer].

To investiage if semantically informed perception had an influence on the ERPs within each phase, planned follow-up comparisons were calculated, contrasting the semantically informed condition against the naive condition within the pre-insight, insight, and post-insight phases.
This was done using the emmeans package [Version `r as.character(packageVersion("emmeans"))`\; @R-emmeans].
All *p*-values were computed by approximating the relevant denominator degrees of freedom using Satterthwaite's method as implemented in the lmerTest package [Version `r as.character(packageVersion("lmerTest"))`\; @R-lmerTest].

## Time-Frequency Analysis

For our exploratory analysis of event-related power, we first created new epochs from the ICA-corrected but unfiltered raw data.
Epochs that were marked as bad for the ERP analysis (i.e., with peak-to-peak amplitudes exceeding `r config$reject_peak_to_peak` µV) were also removed from the time-frequency analysis.
The remaining epochs were convolved with a family of Morlet wavelets, increasing linearly in their frequency from `r min(config$tfr_freqs)` Hz to `r max(config$tfr_freqs)` Hz in steps of `r config$tfr_freqs[2] - config$tfr_freqs[1]` Hz and in their number of cycles from `r min(config$tfr_cycles)` to `r max(config$tfr_cycles)` in steps of `r config$tfr_freqs[2] - config$tfr_cycles[1]` [cf. @samaha2018].
To adjust for the power-law scaling of the human EEG, the power values were transformed into percent signal change by first subtracting and then dividing by the average power at each frequency over the entire epoch [@grandchamp2011].
We then performed baseline correction by subtracting the average during the pre-stimulus interval from `r config$tfr_baseline_tmin` s to `r config$tfr_baseline_tmax` s relative to object onset.

For statistical analysis of event-related power, we conducted cluster-based permutation tests [@maris2007], separately for each of the three phases of the experiment (pre-insight, insight, post-insight).
First, we averaged trials belonging to the same condition and then subtracted these average responses from one another to compute the difference between the semantically informed condition versus the naive condition for each participant.
Then, we conducted one-sample $t$ tests in a mass-univariate fashion and grouped significant results (cluster-forming threshold $p < .05$) into clusters if they ocurred at neighbouring time points, frequencies, or channels.
Neighbouring channels were defined using Delaunay triangulation based on 2D electrode locations as implemented in MNE-Python.
To obtain family-wise error-corrected $p$ values at the cluster level, we compared the cluster mass (i.e., the sum the $t$ values) of each observed cluster to an empirical null distribution of cluster masses obtained from 5,000 permutations with random sign flips.
Clusters were considered to be statistically significant if their mass exceeded the 95^th^ percentile of this distribution (i.e., cluster-level treshold $p < .05$).

## Data and Code Availability

The EEG data are available upon reasonable request from the corresponding author because we had not asked participants for their consent to make the data publicly avaible.
The materials and code for data analysis are available at [https://osf.io/uksbc/](https://osf.io/uksbc/).

# Results

## Event-Related Potentials

Averaged across conditions, P1, N170, and N400 amplitudes differed as a function of the phase of the experiment (pre-insight, insight, or post-insight), all $F$s > `r min(filter(anova_table, effect == "phase")$f_value)`, all $p$s `r print_p(max(filter(anova_table, effect == "phase")$p_value))`.
In addition, N400 amplitudes differed as a function of the condition (semantically informed or naive), averaged across the three phases of the experiment, $F$(`r filter(anova_table, component == "N400" & effect == "condition")$NumDF`, `r filter(anova_table, component == "N400" & effect == "condition")$DenDF`) = `r filter(anova_table, component == "N400" & effect == "condition")$f_value`, $p$ `r print_p(filter(anova_table, component == "N400" & effect == "condition")$p_value)`.
Crucially, the phase × condition interaction was significant for all three ERP components, all $F$s > `r min(filter(anova_table, effect == "phase:condition")$f_value)`, all $p$s < `r print_p(max(filter(anova_table, effect == "phase:condition")$p_value))`.
To answer our main research question, we decomposed these interactions into simple effects of the semantically informed condition versus the naive condition within each of the three phases of the experiment.

In the pre-insight phase, when objects were unfamiliar to participants and presented without keywords, no differences emerged between the semantically informed condition and the naive condition in any of the the ERP components, all $|t|$s < `r max(abs(filter(contrast_table, phase == "Pre-insight")$t_value))`, all $p$ `r print_p(min(filter(contrast_table, phase == "Pre-insight")$p_value))` (Figure \@ref(fig:fig1)B--D).
This was expected given that the critical keywords (leading either to semantically informed perception or to naive perception) had not yet been presented and that the assignment of objects to conditions was counterbalanced across participants as to control for low-level visual differences.

In the insight phase, half of the unfamiliar objects were presented with matching keywords, leading to semanitcally informed perception, and the other half were presented with non-matching keywords, keeping the perception of the objects semantically naive.
Semantically informed perception in this phase was associated with enlarged (i.e., more negative) amplitudes in the N170 component, $b$ = `r filter(contrast_table, component == "N170" & phase == "Insight")$estimate` µV, $t$(`r filter(contrast_table, component == "N170" & phase == "Insight")$df`) = `r filter(contrast_table, component == "N170" & phase == "Insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "N170" & phase == "Insight")$p_value)`, and reduced (i.e., less negative) amplitudes in the N400 component, $b$ = `r filter(contrast_table, component == "N400" & phase == "Insight")$estimate` µV, $t$(`r filter(contrast_table, component == "N400" & phase == "Insight")$df`) = `r filter(contrast_table, component == "N400" & phase == "Insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table, component == "N400" & phase == "Insight")$p_value)`.
There was no reliable difference between conditions in the P1 component, $b$ = `r filter(contrast_table, component == "P1" & phase == "Insight")$estimate` µV, $t$(`r filter(contrast_table, component == "P1" & phase == "Insight")$df`) = `r filter(contrast_table, component == "P1" & phase == "Insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "P1" & phase == "Insight")$p_value)`.

In the post-insight phase, the unfamiliar objects were presented for a third time and without any keywords, mirroring the pre-insight phase.
As in the insight phase, semantically informed perception was associated with reduced (i.e., less negative) amplitudes in the N400 component, $b$ = `r filter(contrast_table, component == "N400" & phase == "Post-insight")$estimate` µV, $t$(`r filter(contrast_table, component == "N400" & phase == "Post-insight")$df`) = `r filter(contrast_table, component == "N400" & phase == "Post-insight")$t_value`, $p_\text{corr}$ `r print_p(filter(contrast_table, component == "N400" & phase == "Post-insight")$p_value)`, while the effect in the N170 component did not recur, $b$ = `r filter(contrast_table, component == "N170" & phase == "Post-insight")$estimate` µV, $t$(`r filter(contrast_table, component == "N170" & phase == "Post-insight")$df`) = `r filter(contrast_table, component == "N170" & phase == "Post-insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "N170" & phase == "Post-insight")$p_value)`.
Instead, the P1 component was significantly enlarged (i.e., more positive) in response to objects for which semantically informed perception had taken place, $b$ = `r filter(contrast_table, component == "P1" & phase == "Post-insight")$estimate` µV, $t$(`r filter(contrast_table, component == "P1" & phase == "Post-insight")$df`) = `r filter(contrast_table, component == "P1" & phase == "Post-insight")$t_value`, $p_\text{corr}$ = `r print_p(filter(contrast_table, component == "P1" & phase == "Post-insight")$p_value)`.

## Event-Related Power

In an exploratory time-frequency analysis, we checked for differences in event-related power between semantically informed perception and naive perception within each of the three phases of the experiment.
Cluster-based permutation tests [@maris2007] revealed no significant clusters in the pre-insight phase (see Figure 2), all $p$s > `r print_p(min(filter(tfr_clusters, contrast == "Pre-insight/Informed - Pre-insight/Naive")$p_val))`, but one significant cluster in the insight phase (see Figure 3), $p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Naive" & p_val < 0.05)$p_val))`, and one significant cluster in the post-insight phase (see Figure 4), $p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Post-insight/Informed - Post-insight/Naive" & p_val < 0.05)$p_val))`.
These two significant clusters in the insight and post-insight phases were similar in their direction, latency, frequency range, and topographic distribution.
Both clusters had a negative sign, started around 600 ms after object onset and continued all the way until the end of the analyzed period at 1,400 ms.
They spanned a broad range of frequencies in the alpha and lower beta range as well as a broad set of channels, but appeared to be most focal at around 15 Hz at parietal channels.
Thus, semantically informed perception seems to alter not only early, evoked activity (see Event-Related Potentials above) but also later, induced activity, in the form of a reduction of post-stimulus power at parietal channels in the range of alpha and lower beta frequencies.

```{r, fig2, fig.height=11, fig.cap="(ref:figure-2-caption)", include=TRUE}
# Create topographic plots for event-related power in each phase
tfr_plots <- plot_fig2(tfr_grand_ave, tfr_clusters, channel_locations)

# Plot Pre-Insight Phase
tfr_plots[[1]]
```

(ref:figure-2-caption) Time-frequency results for the pre-insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
A cluster-based permutation test indicated no clusters for which this difference was statistically significant (all $p$s > `r print_p(min(filter(tfr_clusters, contrast == "Pre-insight/Informed - Pre-insight/Naive")$p_val))`).

```{r, fig3, fig.height=11, fig.cap="(ref:figure-3-caption)", include=TRUE}
# Plot Insight Phase
tfr_plots[[2]]
```

(ref:figure-3-caption) Time-frequency results for the insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
Black dots highlight EEG channels that were part of a cluster for which this difference was statistically significant ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Insight/Informed - Insight/Naive" & p_val < 0.05)$p_val))`).

```{r, fig4, fig.height=11, fig.cap="(ref:figure-4-caption)", include=TRUE}
# Plot Post-Insight Phase
tfr_plots[[3]]
```

(ref:figure-4-caption) Time-frequency results for the post-insight phase.
Each topographic plot shows the difference in event-related power (in units of percent signal change) between the semantically informed condition and the naive condition, grand-averaged across participants.
Black dots highlight EEG channels that were part of a cluster for which this difference was statistically significant ($p_\text{cluster}$ = `r print_p(unique(filter(tfr_clusters, contrast == "Post-insight/Informed - Post-insight/Naive" & p_val < 0.05)$p_val))`).

\newpage

# References

\bigskip

<div id="refs" custom-style="Bibliography"></div>

\newpage
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}

# Supplementary Information

\bigskip

```{r tabs1, include=TRUE, results="asis"}
# Print table of materials
read_tsv(here("materials", "items.txt"), col_types = cols()) %>%
  mutate(
    match_ger = paste0(match_noun_ger, ", ", match_verb_ger),
    match_en = paste0("{[", match_noun_en, ", ", match_verb_en, "]}"),
    nonmatch_ger = paste0(nonmatch_noun_ger, ", ", nonmatch_verb_ger),
    nonmatch_en = paste0("{[", nonmatch_noun_en, ", ", nonmatch_verb_en, "]}"),
  ) %>%
  transmute(
    img = paste0(
      "\\includegraphics[valign=c,scale=0.245]{materials/unfamiliar/",
      item,
      ".png}"
    ),
    item = as.character(item),
    match = paste(match_ger, match_en, sep = "\n") %>%
      kableExtra::linebreak(align = "l", linebreaker = "\n"),
    nonmatch = paste(nonmatch_ger, nonmatch_en, sep = "\n") %>%
      kableExtra::linebreak(align = "l", linebreaker = "\n")
  ) %>%
  apa_table(
    booktabs = TRUE,
    col.names = c(
      "Stimulus", "ID", "Matching keywords", "Non-matching keywords"
    ),
    escape = FALSE,
    longtable = TRUE,
    caption = "Unfamiliar Object Stimuli\\smallskip",
    font_size = "footnotesize"
  )
```

\newpage

## Results S1. *Linear Mixed-Effects Models*

## *P1 Component (100--150 ms)*

\small
\singlespacing

```{r, ress1a, include=TRUE}
# Helper function for printing model summary, ANOVA (F tests), and contrasts
print_model_outputs <- function(model_object) {
  model <- model_object$model
  model@call$data <- NULL # Prevents cluttering the `summary` output
  print(summary(model))
  cat("\n")
  print(model_object$anova)
  cat("\nFollow-Up Contrasts (Simple Effects)\n")
  print(model_object$contrasts)
  cat("\n\n")
}

# Print model outputs
print_model_outputs(models$P1)
```

\newpage
\normalsize
\doublespacing

## *N170 Component (150--200 ms)*

\small
\singlespacing

```{r, ress1b, include=TRUE}
# Print model outputs
print_model_outputs(models$N170)
```

\newpage
\normalsize
\doublespacing

## *N400 Component (400--700 ms)*

\small
\singlespacing

```{r, ress1c, include=TRUE}
# Print model outputs
print_model_outputs(models$N400)
```

\newpage

```{r, figclusters, include=TRUE, fig.height=8}
# Read results of cluster-based permutation tests for ERPs
read_csv(here(output_dir, "clusters.csv"), col_types = cols(
  contrast = col_factor(levels = c(
    "Pre-insight/Informed - Pre-insight/Naive",
    "Insight/Informed - Insight/Naive",
    "Post-insight/Informed - Post-insight/Naive"
  ))
)) -> clusters

# Plot thresholded cluster images
clusters %>%
  filter(p_val < .05) %>%
  ggplot(aes(x = time, y = channel, fill = cluster)) +
  facet_grid(~contrast, drop = FALSE) +
  geom_raster() +
  theme(legend.position = "top")
```

```{r, figtfrclusters, fig.height=12, include=TRUE}
# Read results of cluster-based permutation tests for TFR
read_csv(here(output_dir, "tfr_clusters.csv"), col_types = cols(
  contrast = col_factor(levels = c(
    "Pre-insight/Informed - Pre-insight/Naive",
    "Insight/Informed - Insight/Naive",
    "Post-insight/Informed - Post-insight/Naive"
  ))
)) -> tfr_clusters

# Plot thresholded cluster images for the insight phase
tfr_clusters %>%
  filter(contrast == "Insight/Informed - Insight/Naive" & p_val < .05) %>%
  ggplot(aes(x = time, y = freq, fill = cluster)) +
  facet_wrap(~channel) +
  geom_raster() +
  theme(legend.position = "top")

# Plot thresholded cluster images for the post-insight phase
tfr_clusters %>%
  filter(
    contrast == "Post-insight/Informed - Post-insight/Naive" & p_val < .05
  ) %>%
  ggplot(aes(x = time, y = freq, fill = cluster)) +
  facet_wrap(~channel) +
  geom_raster() +
  theme(legend.position = "top")
```
